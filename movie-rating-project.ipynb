{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../aclImdb/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    25000 non-null  object\n",
      " 1   score   25000 non-null  int64 \n",
      " 2   label   25000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# To see what does the dataset looks like\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     5100\n",
       "10    4732\n",
       "8     3009\n",
       "4     2696\n",
       "7     2496\n",
       "3     2420\n",
       "2     2284\n",
       "9     2263\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lars Von Trier is never backward in trying out new techniques. Some of them are very original while others are best forgotten.<br /><br />He depicts postwar Germany as a nightmarish train journey. With so many cities lying in ruins, Leo Kessler a young American of German descent feels obliged to help in their restoration. It is not a simple task as he quickly finds out.<br /><br />His uncle finds him a job as a night conductor on the Zentropa Railway Line. His job is to attend to the needs of the passengers. When the shoes are polished a chalk mark is made on the soles. A terrible argument ensues when a passenger's shoes are not chalked despite the fact they have been polished. There are many allusions to the German fanaticism of adherence to such stupid details.<br /><br />The railway journey is like an allegory representing man's procession through life with all its trials and tribulations. In one sequence Leo dashes through the back carriages to discover them filled with half-starved bodies appearing to have just escaped from Auschwitz . These images, horrible as they are, are fleeting as in a dream, each with its own terrible impact yet unconnected.<br /><br />At a station called Urmitz Leo jumps from the train with a parceled bomb. In view of many by-standers he connects the bomb to the underside of a carriage. He returns to his cabin and makes a connection to a time clock. Later he jumps from the train (at high speed) and lies in the cool grass on a river bank. Looking at the stars above he decides that his job is to build and not destroy. Subsequently as he sees the train approaching a giant bridge he runs at breakneck speed to board the train and stop the clock. If you care to analyse the situation it is a completely impossible task. Quite ridiculous in fact. It could only happen in a dream.<br /><br />It's strange how one remembers little details such as a row of cups hanging on hooks and rattling away with the swaying of the train.<br /><br />Despite the fact that this film is widely acclaimed, I prefer Lars Von Trier's later films (Breaking the Waves and The Idiots). The bomb scene described above really put me off. Perhaps I'm a realist.\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = dataset['text'].loc[2]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lars Von Trier is never backward in trying out new techniques. Some of them are very original while others are best forgotten.He depicts postwar Germany as a nightmarish train journey. With so many cities lying in ruins, Leo Kessler a young American of German descent feels obliged to help in their restoration. It is not a simple task as he quickly finds out.His uncle finds him a job as a night conductor on the Zentropa Railway Line. His job is to attend to the needs of the passengers. When the shoes are polished a chalk mark is made on the soles. A terrible argument ensues when a passenger's shoes are not chalked despite the fact they have been polished. There are many allusions to the German fanaticism of adherence to such stupid details.The railway journey is like an allegory representing man's procession through life with all its trials and tribulations. In one sequence Leo dashes through the back carriages to discover them filled with half-starved bodies appearing to have just escaped from Auschwitz . These images, horrible as they are, are fleeting as in a dream, each with its own terrible impact yet unconnected.At a station called Urmitz Leo jumps from the train with a parceled bomb. In view of many by-standers he connects the bomb to the underside of a carriage. He returns to his cabin and makes a connection to a time clock. Later he jumps from the train (at high speed) and lies in the cool grass on a river bank. Looking at the stars above he decides that his job is to build and not destroy. Subsequently as he sees the train approaching a giant bridge he runs at breakneck speed to board the train and stop the clock. If you care to analyse the situation it is a completely impossible task. Quite ridiculous in fact. It could only happen in a dream.It's strange how one remembers little details such as a row of cups hanging on hooks and rattling away with the swaying of the train.Despite the fact that this film is widely acclaimed, I prefer Lars Von Trier's later films (Breaking the Waves and The Idiots). The bomb scene described above really put me off. Perhaps I'm a realist.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the raw text data contains html script\n",
    "# So we need to remove html element and clean the data using html.parser from BeautifulSoup\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "#  remove http format and clean text\n",
    "soup = BeautifulSoup(review, \"html.parser\")\n",
    "review = soup.get_text()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lars von trier is never backward in trying out new techniques  some of them are very original while others are best forgotten he depicts postwar germany as a nightmarish train journey  with so many cities lying in ruins  leo kessler a young american of german descent feels obliged to help in their restoration  it is not a simple task as he quickly finds out his uncle finds him a job as a night conductor on the zentropa railway line  his job is to attend to the needs of the passengers  when the shoes are polished a chalk mark is made on the soles  a terrible argument ensues when a passenger s shoes are not chalked despite the fact they have been polished  there are many allusions to the german fanaticism of adherence to such stupid details the railway journey is like an allegory representing man s procession through life with all its trials and tribulations  in one sequence leo dashes through the back carriages to discover them filled with half starved bodies appearing to have just escaped from auschwitz   these images  horrible as they are  are fleeting as in a dream  each with its own terrible impact yet unconnected at a station called urmitz leo jumps from the train with a parceled bomb  in view of many by standers he connects the bomb to the underside of a carriage  he returns to his cabin and makes a connection to a time clock  later he jumps from the train  at high speed  and lies in the cool grass on a river bank  looking at the stars above he decides that his job is to build and not destroy  subsequently as he sees the train approaching a giant bridge he runs at breakneck speed to board the train and stop the clock  if you care to analyse the situation it is a completely impossible task  quite ridiculous in fact  it could only happen in a dream it s strange how one remembers little details such as a row of cups hanging on hooks and rattling away with the swaying of the train despite the fact that this film is widely acclaimed  i prefer lars von trier s later films  breaking the waves and the idiots   the bomb scene described above really put me off  perhaps i m a realist '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use re regular equation to convert text to lower case\n",
    "import re\n",
    "review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "review = review.lower()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 'is',\n",
       " 'never',\n",
       " 'backward',\n",
       " 'in',\n",
       " 'trying',\n",
       " 'out',\n",
       " 'new',\n",
       " 'techniques',\n",
       " 'some',\n",
       " 'of',\n",
       " 'them',\n",
       " 'are',\n",
       " 'very',\n",
       " 'original',\n",
       " 'while',\n",
       " 'others',\n",
       " 'are',\n",
       " 'best',\n",
       " 'forgotten',\n",
       " 'he',\n",
       " 'depicts',\n",
       " 'postwar',\n",
       " 'germany',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nightmarish',\n",
       " 'train',\n",
       " 'journey',\n",
       " 'with',\n",
       " 'so',\n",
       " 'many',\n",
       " 'cities',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'ruins',\n",
       " 'leo',\n",
       " 'kessler',\n",
       " 'a',\n",
       " 'young',\n",
       " 'american',\n",
       " 'of',\n",
       " 'german',\n",
       " 'descent',\n",
       " 'feels',\n",
       " 'obliged',\n",
       " 'to',\n",
       " 'help',\n",
       " 'in',\n",
       " 'their',\n",
       " 'restoration',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'simple',\n",
       " 'task',\n",
       " 'as',\n",
       " 'he',\n",
       " 'quickly',\n",
       " 'finds',\n",
       " 'out',\n",
       " 'his',\n",
       " 'uncle',\n",
       " 'finds',\n",
       " 'him',\n",
       " 'a',\n",
       " 'job',\n",
       " 'as',\n",
       " 'a',\n",
       " 'night',\n",
       " 'conductor',\n",
       " 'on',\n",
       " 'the',\n",
       " 'zentropa',\n",
       " 'railway',\n",
       " 'line',\n",
       " 'his',\n",
       " 'job',\n",
       " 'is',\n",
       " 'to',\n",
       " 'attend',\n",
       " 'to',\n",
       " 'the',\n",
       " 'needs',\n",
       " 'of',\n",
       " 'the',\n",
       " 'passengers',\n",
       " 'when',\n",
       " 'the',\n",
       " 'shoes',\n",
       " 'are',\n",
       " 'polished',\n",
       " 'a',\n",
       " 'chalk',\n",
       " 'mark',\n",
       " 'is',\n",
       " 'made',\n",
       " 'on',\n",
       " 'the',\n",
       " 'soles',\n",
       " 'a',\n",
       " 'terrible',\n",
       " 'argument',\n",
       " 'ensues',\n",
       " 'when',\n",
       " 'a',\n",
       " 'passenger',\n",
       " 's',\n",
       " 'shoes',\n",
       " 'are',\n",
       " 'not',\n",
       " 'chalked',\n",
       " 'despite',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'they',\n",
       " 'have',\n",
       " 'been',\n",
       " 'polished',\n",
       " 'there',\n",
       " 'are',\n",
       " 'many',\n",
       " 'allusions',\n",
       " 'to',\n",
       " 'the',\n",
       " 'german',\n",
       " 'fanaticism',\n",
       " 'of',\n",
       " 'adherence',\n",
       " 'to',\n",
       " 'such',\n",
       " 'stupid',\n",
       " 'details',\n",
       " 'the',\n",
       " 'railway',\n",
       " 'journey',\n",
       " 'is',\n",
       " 'like',\n",
       " 'an',\n",
       " 'allegory',\n",
       " 'representing',\n",
       " 'man',\n",
       " 's',\n",
       " 'procession',\n",
       " 'through',\n",
       " 'life',\n",
       " 'with',\n",
       " 'all',\n",
       " 'its',\n",
       " 'trials',\n",
       " 'and',\n",
       " 'tribulations',\n",
       " 'in',\n",
       " 'one',\n",
       " 'sequence',\n",
       " 'leo',\n",
       " 'dashes',\n",
       " 'through',\n",
       " 'the',\n",
       " 'back',\n",
       " 'carriages',\n",
       " 'to',\n",
       " 'discover',\n",
       " 'them',\n",
       " 'filled',\n",
       " 'with',\n",
       " 'half',\n",
       " 'starved',\n",
       " 'bodies',\n",
       " 'appearing',\n",
       " 'to',\n",
       " 'have',\n",
       " 'just',\n",
       " 'escaped',\n",
       " 'from',\n",
       " 'auschwitz',\n",
       " 'these',\n",
       " 'images',\n",
       " 'horrible',\n",
       " 'as',\n",
       " 'they',\n",
       " 'are',\n",
       " 'are',\n",
       " 'fleeting',\n",
       " 'as',\n",
       " 'in',\n",
       " 'a',\n",
       " 'dream',\n",
       " 'each',\n",
       " 'with',\n",
       " 'its',\n",
       " 'own',\n",
       " 'terrible',\n",
       " 'impact',\n",
       " 'yet',\n",
       " 'unconnected',\n",
       " 'at',\n",
       " 'a',\n",
       " 'station',\n",
       " 'called',\n",
       " 'urmitz',\n",
       " 'leo',\n",
       " 'jumps',\n",
       " 'from',\n",
       " 'the',\n",
       " 'train',\n",
       " 'with',\n",
       " 'a',\n",
       " 'parceled',\n",
       " 'bomb',\n",
       " 'in',\n",
       " 'view',\n",
       " 'of',\n",
       " 'many',\n",
       " 'by',\n",
       " 'standers',\n",
       " 'he',\n",
       " 'connects',\n",
       " 'the',\n",
       " 'bomb',\n",
       " 'to',\n",
       " 'the',\n",
       " 'underside',\n",
       " 'of',\n",
       " 'a',\n",
       " 'carriage',\n",
       " 'he',\n",
       " 'returns',\n",
       " 'to',\n",
       " 'his',\n",
       " 'cabin',\n",
       " 'and',\n",
       " 'makes',\n",
       " 'a',\n",
       " 'connection',\n",
       " 'to',\n",
       " 'a',\n",
       " 'time',\n",
       " 'clock',\n",
       " 'later',\n",
       " 'he',\n",
       " 'jumps',\n",
       " 'from',\n",
       " 'the',\n",
       " 'train',\n",
       " 'at',\n",
       " 'high',\n",
       " 'speed',\n",
       " 'and',\n",
       " 'lies',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cool',\n",
       " 'grass',\n",
       " 'on',\n",
       " 'a',\n",
       " 'river',\n",
       " 'bank',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'above',\n",
       " 'he',\n",
       " 'decides',\n",
       " 'that',\n",
       " 'his',\n",
       " 'job',\n",
       " 'is',\n",
       " 'to',\n",
       " 'build',\n",
       " 'and',\n",
       " 'not',\n",
       " 'destroy',\n",
       " 'subsequently',\n",
       " 'as',\n",
       " 'he',\n",
       " 'sees',\n",
       " 'the',\n",
       " 'train',\n",
       " 'approaching',\n",
       " 'a',\n",
       " 'giant',\n",
       " 'bridge',\n",
       " 'he',\n",
       " 'runs',\n",
       " 'at',\n",
       " 'breakneck',\n",
       " 'speed',\n",
       " 'to',\n",
       " 'board',\n",
       " 'the',\n",
       " 'train',\n",
       " 'and',\n",
       " 'stop',\n",
       " 'the',\n",
       " 'clock',\n",
       " 'if',\n",
       " 'you',\n",
       " 'care',\n",
       " 'to',\n",
       " 'analyse',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'completely',\n",
       " 'impossible',\n",
       " 'task',\n",
       " 'quite',\n",
       " 'ridiculous',\n",
       " 'in',\n",
       " 'fact',\n",
       " 'it',\n",
       " 'could',\n",
       " 'only',\n",
       " 'happen',\n",
       " 'in',\n",
       " 'a',\n",
       " 'dream',\n",
       " 'it',\n",
       " 's',\n",
       " 'strange',\n",
       " 'how',\n",
       " 'one',\n",
       " 'remembers',\n",
       " 'little',\n",
       " 'details',\n",
       " 'such',\n",
       " 'as',\n",
       " 'a',\n",
       " 'row',\n",
       " 'of',\n",
       " 'cups',\n",
       " 'hanging',\n",
       " 'on',\n",
       " 'hooks',\n",
       " 'and',\n",
       " 'rattling',\n",
       " 'away',\n",
       " 'with',\n",
       " 'the',\n",
       " 'swaying',\n",
       " 'of',\n",
       " 'the',\n",
       " 'train',\n",
       " 'despite',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'this',\n",
       " 'film',\n",
       " 'is',\n",
       " 'widely',\n",
       " 'acclaimed',\n",
       " 'i',\n",
       " 'prefer',\n",
       " 'lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 's',\n",
       " 'later',\n",
       " 'films',\n",
       " 'breaking',\n",
       " 'the',\n",
       " 'waves',\n",
       " 'and',\n",
       " 'the',\n",
       " 'idiots',\n",
       " 'the',\n",
       " 'bomb',\n",
       " 'scene',\n",
       " 'described',\n",
       " 'above',\n",
       " 'really',\n",
       " 'put',\n",
       " 'me',\n",
       " 'off',\n",
       " 'perhaps',\n",
       " 'i',\n",
       " 'm',\n",
       " 'a',\n",
       " 'realist']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.split()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/wenkanw/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 'never',\n",
       " 'backward',\n",
       " 'trying',\n",
       " 'new',\n",
       " 'techniques',\n",
       " 'original',\n",
       " 'others',\n",
       " 'best',\n",
       " 'forgotten',\n",
       " 'depicts',\n",
       " 'postwar',\n",
       " 'germany',\n",
       " 'nightmarish',\n",
       " 'train',\n",
       " 'journey',\n",
       " 'many',\n",
       " 'cities',\n",
       " 'lying',\n",
       " 'ruins',\n",
       " 'leo',\n",
       " 'kessler',\n",
       " 'young',\n",
       " 'american',\n",
       " 'german',\n",
       " 'descent',\n",
       " 'feels',\n",
       " 'obliged',\n",
       " 'help',\n",
       " 'restoration',\n",
       " 'simple',\n",
       " 'task',\n",
       " 'quickly',\n",
       " 'finds',\n",
       " 'uncle',\n",
       " 'finds',\n",
       " 'job',\n",
       " 'night',\n",
       " 'conductor',\n",
       " 'zentropa',\n",
       " 'railway',\n",
       " 'line',\n",
       " 'job',\n",
       " 'attend',\n",
       " 'needs',\n",
       " 'passengers',\n",
       " 'shoes',\n",
       " 'polished',\n",
       " 'chalk',\n",
       " 'mark',\n",
       " 'made',\n",
       " 'soles',\n",
       " 'terrible',\n",
       " 'argument',\n",
       " 'ensues',\n",
       " 'passenger',\n",
       " 'shoes',\n",
       " 'chalked',\n",
       " 'despite',\n",
       " 'fact',\n",
       " 'polished',\n",
       " 'many',\n",
       " 'allusions',\n",
       " 'german',\n",
       " 'fanaticism',\n",
       " 'adherence',\n",
       " 'stupid',\n",
       " 'details',\n",
       " 'railway',\n",
       " 'journey',\n",
       " 'like',\n",
       " 'allegory',\n",
       " 'representing',\n",
       " 'man',\n",
       " 'procession',\n",
       " 'life',\n",
       " 'trials',\n",
       " 'tribulations',\n",
       " 'one',\n",
       " 'sequence',\n",
       " 'leo',\n",
       " 'dashes',\n",
       " 'back',\n",
       " 'carriages',\n",
       " 'discover',\n",
       " 'filled',\n",
       " 'half',\n",
       " 'starved',\n",
       " 'bodies',\n",
       " 'appearing',\n",
       " 'escaped',\n",
       " 'auschwitz',\n",
       " 'images',\n",
       " 'horrible',\n",
       " 'fleeting',\n",
       " 'dream',\n",
       " 'terrible',\n",
       " 'impact',\n",
       " 'yet',\n",
       " 'unconnected',\n",
       " 'station',\n",
       " 'called',\n",
       " 'urmitz',\n",
       " 'leo',\n",
       " 'jumps',\n",
       " 'train',\n",
       " 'parceled',\n",
       " 'bomb',\n",
       " 'view',\n",
       " 'many',\n",
       " 'standers',\n",
       " 'connects',\n",
       " 'bomb',\n",
       " 'underside',\n",
       " 'carriage',\n",
       " 'returns',\n",
       " 'cabin',\n",
       " 'makes',\n",
       " 'connection',\n",
       " 'time',\n",
       " 'clock',\n",
       " 'later',\n",
       " 'jumps',\n",
       " 'train',\n",
       " 'high',\n",
       " 'speed',\n",
       " 'lies',\n",
       " 'cool',\n",
       " 'grass',\n",
       " 'river',\n",
       " 'bank',\n",
       " 'looking',\n",
       " 'stars',\n",
       " 'decides',\n",
       " 'job',\n",
       " 'build',\n",
       " 'destroy',\n",
       " 'subsequently',\n",
       " 'sees',\n",
       " 'train',\n",
       " 'approaching',\n",
       " 'giant',\n",
       " 'bridge',\n",
       " 'runs',\n",
       " 'breakneck',\n",
       " 'speed',\n",
       " 'board',\n",
       " 'train',\n",
       " 'stop',\n",
       " 'clock',\n",
       " 'care',\n",
       " 'analyse',\n",
       " 'situation',\n",
       " 'completely',\n",
       " 'impossible',\n",
       " 'task',\n",
       " 'quite',\n",
       " 'ridiculous',\n",
       " 'fact',\n",
       " 'could',\n",
       " 'happen',\n",
       " 'dream',\n",
       " 'strange',\n",
       " 'one',\n",
       " 'remembers',\n",
       " 'little',\n",
       " 'details',\n",
       " 'row',\n",
       " 'cups',\n",
       " 'hanging',\n",
       " 'hooks',\n",
       " 'rattling',\n",
       " 'away',\n",
       " 'swaying',\n",
       " 'train',\n",
       " 'despite',\n",
       " 'fact',\n",
       " 'film',\n",
       " 'widely',\n",
       " 'acclaimed',\n",
       " 'prefer',\n",
       " 'lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 'later',\n",
       " 'films',\n",
       " 'breaking',\n",
       " 'waves',\n",
       " 'idiots',\n",
       " 'bomb',\n",
       " 'scene',\n",
       " 'described',\n",
       " 'really',\n",
       " 'put',\n",
       " 'perhaps',\n",
       " 'realist']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#remove stop words here since stop words don't contain information related to sentiment / rating \n",
    "review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 'never',\n",
       " 'backward',\n",
       " 'trying',\n",
       " 'new',\n",
       " 'technique',\n",
       " 'original',\n",
       " 'others',\n",
       " 'best',\n",
       " 'forgotten',\n",
       " 'depicts',\n",
       " 'postwar',\n",
       " 'germany',\n",
       " 'nightmarish',\n",
       " 'train',\n",
       " 'journey',\n",
       " 'many',\n",
       " 'city',\n",
       " 'lying',\n",
       " 'ruin',\n",
       " 'leo',\n",
       " 'kessler',\n",
       " 'young',\n",
       " 'american',\n",
       " 'german',\n",
       " 'descent',\n",
       " 'feel',\n",
       " 'obliged',\n",
       " 'help',\n",
       " 'restoration',\n",
       " 'simple',\n",
       " 'task',\n",
       " 'quickly',\n",
       " 'find',\n",
       " 'uncle',\n",
       " 'find',\n",
       " 'job',\n",
       " 'night',\n",
       " 'conductor',\n",
       " 'zentropa',\n",
       " 'railway',\n",
       " 'line',\n",
       " 'job',\n",
       " 'attend',\n",
       " 'need',\n",
       " 'passenger',\n",
       " 'shoe',\n",
       " 'polished',\n",
       " 'chalk',\n",
       " 'mark',\n",
       " 'made',\n",
       " 'sol',\n",
       " 'terrible',\n",
       " 'argument',\n",
       " 'ensues',\n",
       " 'passenger',\n",
       " 'shoe',\n",
       " 'chalked',\n",
       " 'despite',\n",
       " 'fact',\n",
       " 'polished',\n",
       " 'many',\n",
       " 'allusion',\n",
       " 'german',\n",
       " 'fanaticism',\n",
       " 'adherence',\n",
       " 'stupid',\n",
       " 'detail',\n",
       " 'railway',\n",
       " 'journey',\n",
       " 'like',\n",
       " 'allegory',\n",
       " 'representing',\n",
       " 'man',\n",
       " 'procession',\n",
       " 'life',\n",
       " 'trial',\n",
       " 'tribulation',\n",
       " 'one',\n",
       " 'sequence',\n",
       " 'leo',\n",
       " 'dash',\n",
       " 'back',\n",
       " 'carriage',\n",
       " 'discover',\n",
       " 'filled',\n",
       " 'half',\n",
       " 'starved',\n",
       " 'body',\n",
       " 'appearing',\n",
       " 'escaped',\n",
       " 'auschwitz',\n",
       " 'image',\n",
       " 'horrible',\n",
       " 'fleeting',\n",
       " 'dream',\n",
       " 'terrible',\n",
       " 'impact',\n",
       " 'yet',\n",
       " 'unconnected',\n",
       " 'station',\n",
       " 'called',\n",
       " 'urmitz',\n",
       " 'leo',\n",
       " 'jump',\n",
       " 'train',\n",
       " 'parceled',\n",
       " 'bomb',\n",
       " 'view',\n",
       " 'many',\n",
       " 'stander',\n",
       " 'connects',\n",
       " 'bomb',\n",
       " 'underside',\n",
       " 'carriage',\n",
       " 'return',\n",
       " 'cabin',\n",
       " 'make',\n",
       " 'connection',\n",
       " 'time',\n",
       " 'clock',\n",
       " 'later',\n",
       " 'jump',\n",
       " 'train',\n",
       " 'high',\n",
       " 'speed',\n",
       " 'lie',\n",
       " 'cool',\n",
       " 'grass',\n",
       " 'river',\n",
       " 'bank',\n",
       " 'looking',\n",
       " 'star',\n",
       " 'decides',\n",
       " 'job',\n",
       " 'build',\n",
       " 'destroy',\n",
       " 'subsequently',\n",
       " 'see',\n",
       " 'train',\n",
       " 'approaching',\n",
       " 'giant',\n",
       " 'bridge',\n",
       " 'run',\n",
       " 'breakneck',\n",
       " 'speed',\n",
       " 'board',\n",
       " 'train',\n",
       " 'stop',\n",
       " 'clock',\n",
       " 'care',\n",
       " 'analyse',\n",
       " 'situation',\n",
       " 'completely',\n",
       " 'impossible',\n",
       " 'task',\n",
       " 'quite',\n",
       " 'ridiculous',\n",
       " 'fact',\n",
       " 'could',\n",
       " 'happen',\n",
       " 'dream',\n",
       " 'strange',\n",
       " 'one',\n",
       " 'remembers',\n",
       " 'little',\n",
       " 'detail',\n",
       " 'row',\n",
       " 'cup',\n",
       " 'hanging',\n",
       " 'hook',\n",
       " 'rattling',\n",
       " 'away',\n",
       " 'swaying',\n",
       " 'train',\n",
       " 'despite',\n",
       " 'fact',\n",
       " 'film',\n",
       " 'widely',\n",
       " 'acclaimed',\n",
       " 'prefer',\n",
       " 'lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 'later',\n",
       " 'film',\n",
       " 'breaking',\n",
       " 'wave',\n",
       " 'idiot',\n",
       " 'bomb',\n",
       " 'scene',\n",
       " 'described',\n",
       " 'really',\n",
       " 'put',\n",
       " 'perhaps',\n",
       " 'realist']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# lemmatizer words, re-form the distorted words\n",
    "\n",
    "# if use stemmer, deannotate the following line. But Lemmatizer is better than stemmer\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "lem = WordNetLemmatizer()\n",
    "review = [lem.lemmatize(word) for word in review]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lars von trier never backward trying new technique original others best forgotten depicts postwar germany nightmarish train journey many city lying ruin leo kessler young american german descent feel obliged help restoration simple task quickly find uncle find job night conductor zentropa railway line job attend need passenger shoe polished chalk mark made sol terrible argument ensues passenger shoe chalked despite fact polished many allusion german fanaticism adherence stupid detail railway journey like allegory representing man procession life trial tribulation one sequence leo dash back carriage discover filled half starved body appearing escaped auschwitz image horrible fleeting dream terrible impact yet unconnected station called urmitz leo jump train parceled bomb view many stander connects bomb underside carriage return cabin make connection time clock later jump train high speed lie cool grass river bank looking star decides job build destroy subsequently see train approaching giant bridge run breakneck speed board train stop clock care analyse situation completely impossible task quite ridiculous fact could happen dream strange one remembers little detail row cup hanging hook rattling away swaying train despite fact film widely acclaimed prefer lars von trier later film breaking wave idiot bomb scene described really put perhaps realist'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1,\n",
       "        1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "        1, 2, 1, 2, 1, 1, 3, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 1, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "        1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 6, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "        1, 2, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with count vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# count_vec= CountVectorizer(binary=True)  #convert count to binary 0 1 values\n",
    "count_vec= CountVectorizer()\n",
    "review_count_vec= count_vec.fit_transform(corpus)\n",
    "review_count_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.1726306 , 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.11508707, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.11508707, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.11508707, 0.05754353,\n",
       "        0.11508707, 0.05754353, 0.11508707, 0.05754353, 0.05754353,\n",
       "        0.1726306 , 0.05754353, 0.05754353, 0.05754353, 0.11508707,\n",
       "        0.11508707, 0.05754353, 0.05754353, 0.11508707, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.1726306 , 0.11508707,\n",
       "        0.11508707, 0.05754353, 0.11508707, 0.11508707, 0.1726306 ,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.1726306 , 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.11508707, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.11508707, 0.05754353, 0.11508707,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.11508707, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.11508707, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.11508707, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.11508707, 0.05754353, 0.11508707, 0.05754353,\n",
       "        0.3452612 , 0.05754353, 0.05754353, 0.11508707, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.11508707, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with TFIDF vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "review_tfidf_vec = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "review_tfidf_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_train = dataset['text']\n",
    "train_data_label = dataset['label']\n",
    "testdata = pd.read_csv(\"../aclImdb/test.csv\")\n",
    "dataset_test= testdata['text']\n",
    "test_data_label = testdata['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_label.shape, train_data_label.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Previous reviewer Claudio Carvalho gave a much better recap of the film's plot details than I could. What I recall mostly is that it was just so beautiful, in every sense - emotionally, visually, editorially - just gorgeous.<br /><br />If you like movies that are wonderful to look at, and also have emotional content to which that beauty is relevant, I think you will be glad to have seen this extraordinary and unusual work of art.<br /><br />On a scale of 1 to 10, I'd give it about an 8.75. The only reason I shy away from 9 is that it is a mood piece. If you are in the mood for a really artistic, very romantic film, then it's a 10. I definitely think it's a must-see, but none of us can be in that mood all the time, so, overall, 8.75.\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postwar Europe. Like TTM, there is much inventive camera work. There is an innocent American who gets emotionally involved with a woman he doesn\\'t really understand, and whose naivety is all the more striking in contrast with the natives.<br /><br />But I\\'d have to say that The Third Man has a more well-crafted storyline. Zentropa is a bit disjointed in this respect. Perhaps this is intentional: it is presented as a dream/nightmare, and making it too coherent would spoil the effect. <br /><br />This movie is unrelentingly grim--\"noir\" in more than one sense; one never sees the sun shine. Grim, but intriguing, and frightening.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_data(dataset):\n",
    "    corpus_data= []\n",
    "    for i in range(dataset.shape[0]):\n",
    "        soup = BeautifulSoup(dataset.iloc[i], \"html.parser\")\n",
    "        review = soup.get_text()\n",
    "        review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "        review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        # remove stopwords\n",
    "        review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "        # lemmatize the distorted words\n",
    "        lem = WordNetLemmatizer()\n",
    "        review = [lem.lemmatize(word) for word in review]\n",
    "        review = ' '.join(review)\n",
    "        # cleaned text data\n",
    "        corpus_data.append(review)\n",
    "    return corpus_data\n",
    "\n",
    "# corpus_train = []\n",
    "# corpus_test  = []\n",
    "\n",
    "# for i in range(dataset_train.shape[0]):\n",
    "#     soup = BeautifulSoup(dataset_train.iloc[i], \"html.parser\")\n",
    "#     review = soup.get_text()\n",
    "#     review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "#     review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "#     review = review.lower()\n",
    "#     review = review.split()\n",
    "#     review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "#     lem = WordNetLemmatizer()\n",
    "#     review = [lem.lemmatize(word) for word in review]\n",
    "#     review = ' '.join(review)\n",
    "#     corpus_train.append(review)\n",
    "    \n",
    "# for j in range(dataset_test.shape[0]):\n",
    "#     soup = BeautifulSoup(dataset_test.iloc[j], \"html.parser\")\n",
    "#     review = soup.get_text()\n",
    "#     review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "#     review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "#     review = review.lower()\n",
    "#     review = review.split()\n",
    "#     review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "#     lem = WordNetLemmatizer()\n",
    "#     review = [lem.lemmatize(word) for word in review]\n",
    "#     review = ' '.join(review)\n",
    "#     corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_train = transform_data(dataset_train[:10000])\n",
    "# corpus_test = transform_data(dataset_test[:5000])\n",
    "corpus_train = transform_data(dataset_train)\n",
    "corpus_test = transform_data(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def save_clean_data(train_txt, train_label,train_score, test_txt,test_label,test_score):\n",
    "    fp = open(\"cleaned_train.csv\",\"w+\")\n",
    "    fieldnames = [\"text\",\"label\",\"score\"]\n",
    "    writer = csv.DictWriter(fp, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(train_txt)):\n",
    "        writer.writerow({'text': train_txt[i], 'label': train_label[i],'score':train_score[i]})\n",
    "    fp.close()\n",
    "    \n",
    "    test_fp = open(\"cleaned_test.csv\",\"w+\")\n",
    "    fieldnames = [\"text\",\"label\",\"score\"]\n",
    "    writer = csv.DictWriter(test_fp, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(train_txt)):\n",
    "        \n",
    "        writer.writerow({'text': test_txt[i], 'label': test_label[i],'score':test_score[i]})\n",
    "    test_fp.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save cleaned text data for future use\n",
    "# save_clean_data(corpus_train,dataset['label'],dataset['score'],corpus_test, testdata['label'],testdata['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text dataset  that have been cleaned\n",
    "\n",
    "clean_data = pd.read_csv(\"cleaned_train.csv\")\n",
    "clean_test = pd.read_csv(\"cleaned_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test = clean_test['text']\n",
    "corpus_train = clean_data['text']\n",
    "len(clean_data),len(clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes awa wrestling anyone forget unreal show first short interviewer named marty neil made rock n roll buck zumhofe look like nose tackle gene okerland got mad wrestler would say either time well right back acting like mad actually sounding forced went wwf ken resneck took even though mustache looked like week old soup got stuck fine interviewer georgeous jimmy garvin called mouse face made fall chair laughing jumped ship larry nelson came board bad phyllis george would improvement doug mcleod best wrestling announcer ever made every match exciting description blow offered pay minnesota north star hockey team ringside forget roger kent mispronouncing word sentence historic like wrestler big he big punched kicked gut right gusset kicked punted piledriver banned nick bockwinkle used helpless opponent right roger like care left greener money wwf rod trongard announcing style great different like wrestler scraped sole boot across another guy forehead say right across front e lobe wrestler trouble he bad bad way also would say awa baddest toughest meanest scientific wrestler right awa extra money verne gagne left wwf larry wheres phyllis nelson took would talk someone else totally ignore wwe wisely take also greg gagne ugliest wrestling boot ever saw yellow color something want say also he looking tag look like want get run nearest restroom jumpin jim brunzell great dropkick artist wonder greg ever partner jerry blackwell rip also superstar wrestler wonder verne win puhleeeeze vince mcmahon would hire gagnes jobber would make wrestle squash match like see gagne family say wrestling real'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['text'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes AWA wrestling how can anyone forget about this unreal show. First they had a very short interviewer named Marty O\\'Neil who made \"Rock n Roll\" Buck Zumhofe look like a nose tackle. Then it was Gene Okerland who when he got \"mad as the wrestler\" would say either \"Were out of time\" or \"Well be right back\" acting like he was mad but actually sounding forced. After he went to the WWF Ken Resneck took over even though his mustache looked like week old soup got stuck to it was a very fine interviewer who \"Georgeous\" Jimmy Garvin called mouse face which made me fall off my chair laughing. After he jumped ship then Larry Nelson came on board which he was so bad that Phyllis George would of been an improvement! Then there\\'s Doug McLeod the best wrestling announcer ever who made every match exciting with his description of blows! Then he was offered more pay by the Minnesota North Stars hockey team. At ringside who can forget Roger Kent who\\'s mispronouncing of words and sentences were historic Like when a wrestler was big \"Hes a big-on!\" punched or kicked in the guts \"right in the gussets\"or when kicked \"He punted him\" or \"the \"piledriver should be banned\" after Nick Bockwinkle used it on a helpless opponent.(Right Roger like you care!) After he left to greener money(WWF) they had Rod Trongard who\\'s announcing style was great but different. Like when a wrestler scraped the sole of his boot across another guys forehead he\\'d say\"Right across the front-e-lobe\" or when a wrestler is in trouble \"Hes in a bad bad way\". He also would say AWA the baddest,toughest,meanest, most scientific wrestlers are here right in the AWA!(No extra money Verne Gagne!) After he left(WWF) Larry(Wheres Phyllis?!) Nelson took over and I would talk to someone else or totally ignore him.(WWE wisely didn\\'t take him!) Also Greg Gagne had the ugliest wrestling boots I ever saw a yellow color of something I don\\'t want to say.Also when hes looking for the tag he looks like he wants to get it over with so that he can run to the nearest restroom! Jumpin Jim Brunzell was such a great dropkick artist that you wonder why Greg was ever his partner. Jerry Blackwell(RIP)was also a superstar wrestler but you wonder why Verne had himself win against him.(Puhleeeeze!) Then when Vince McMahon would hire Gagnes jobbers, he would make most of them wrestle squash matches. I like to see the Gagne family say wrestlings real now!'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>, <Managed Device 1>\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TFIDF\n",
    "# n_gram: the number of char in a word\n",
    "# if using n_gram=3, then in [\"I Like dog so much\"] sentence, it is broken into [\"I like dog\", \"like dog so\", \"dog so much\"]\n",
    "# gram means the size of window that contains consecutive words\n",
    "\n",
    "#Note: Tfidf vectorizer already normalize the data and avoid zero-division by setting flag:  smooth_idf=True\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tfidf_vec_train = tfidf_vec.fit_transform(corpus_train)\n",
    "tfidf_vec_test = tfidf_vec.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using count vectorizer\n",
    "count_vec = CountVectorizer(ngram_range=(1, 3), binary=False)\n",
    "count_vec_train = count_vec.fit_transform(corpus_train)\n",
    "count_vec_test = count_vec.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8202611, 8202611)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(tfidf_vec_train.data),len(count_vec_train.data)\n",
    "# la = np.linalg\n",
    "# U,s, Vp = la.svd(count_vec_train,full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 4485967), (25000, 4485967))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec_train.shape, tfidf_vec_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label types: rating from 1 to 10\n",
    "target_names = set(dataset['score'])\n",
    "target_names= list(target_names)\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91048"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(C=0.1, random_state=40).fit(tfidf_vec_train, dataset['score'])\n",
    "#train corpus score\n",
    "clf.score(tfidf_vec_train, dataset['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.51      0.44      5022\n",
      "           2       0.19      0.13      0.16      2302\n",
      "           3       0.19      0.16      0.17      2541\n",
      "           4       0.23      0.21      0.22      2635\n",
      "           7       0.19      0.18      0.19      2307\n",
      "           8       0.23      0.23      0.23      2850\n",
      "           9       0.19      0.15      0.17      2344\n",
      "          10       0.40      0.44      0.42      4999\n",
      "\n",
      "    accuracy                           0.30     25000\n",
      "   macro avg       0.25      0.25      0.25     25000\n",
      "weighted avg       0.28      0.30      0.29     25000\n",
      "\n",
      "Accuracy: \n",
      " 0.29736\n"
     ]
    }
   ],
   "source": [
    "# clf.score(tfidf_vec_test, testdata['score'])\n",
    "test_label = testdata['score']\n",
    "pred = clf.predict(tfidf_vec_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(test_label, pred,  labels = target_names))\n",
    "print(\"Accuracy: \\n\", accuracy_score(testdata['score'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90388"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression( solver = 'sag', random_state=0).fit(tfidf_vec_train, dataset['score'])\n",
    "#train corpus score\n",
    "lr_clf.score(tfidf_vec_train, dataset['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.50      0.44      5022\n",
      "           2       0.19      0.13      0.15      2302\n",
      "           3       0.19      0.15      0.17      2541\n",
      "           4       0.22      0.21      0.22      2635\n",
      "           7       0.19      0.18      0.18      2307\n",
      "           8       0.23      0.23      0.23      2850\n",
      "           9       0.19      0.14      0.16      2344\n",
      "          10       0.39      0.45      0.42      4999\n",
      "\n",
      "    accuracy                           0.30     25000\n",
      "   macro avg       0.25      0.25      0.25     25000\n",
      "weighted avg       0.28      0.30      0.28     25000\n",
      "\n",
      "Accuracy: \n",
      " 0.29512\n"
     ]
    }
   ],
   "source": [
    "test_label = testdata['score']\n",
    "lr_pred = lr_clf.predict(tfidf_vec_test)\n",
    "print(classification_report(test_label, lr_pred,  labels = target_names))\n",
    "print(\"Accuracy: \\n\", accuracy_score(testdata['score'], lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68652"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "svc_clf = LinearSVC(C=0.05).fit(tfidf_vec_train, dataset['score'])\n",
    "svc_clf.score(tfidf_vec_train, dataset['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.70      0.49      5022\n",
      "           2       0.18      0.04      0.06      2302\n",
      "           3       0.19      0.07      0.10      2541\n",
      "           4       0.23      0.15      0.18      2635\n",
      "           7       0.19      0.14      0.16      2307\n",
      "           8       0.24      0.18      0.21      2850\n",
      "           9       0.20      0.05      0.08      2344\n",
      "          10       0.37      0.61      0.46      4999\n",
      "\n",
      "    accuracy                           0.33     25000\n",
      "   macro avg       0.25      0.24      0.22     25000\n",
      "weighted avg       0.27      0.33      0.27     25000\n",
      "\n",
      "Accuracy: \n",
      " 0.32632\n"
     ]
    }
   ],
   "source": [
    "svc_pred = svc_clf.predict(tfidf_vec_test)\n",
    "test_label = testdata['score']\n",
    "print(classification_report(test_label, svc_pred,  labels = target_names))\n",
    "print(\"Accuracy: \\n\", accuracy_score(testdata['score'], svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My default: Python3.7.7",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
