{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../aclImdb/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    25000 non-null  object\n",
      " 1   score   25000 non-null  int64 \n",
      " 2   label   25000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# To see what does the dataset looks like\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     5100\n",
       "10    4732\n",
       "8     3009\n",
       "4     2696\n",
       "7     2496\n",
       "3     2420\n",
       "2     2284\n",
       "9     2263\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lars Von Trier is never backward in trying out new techniques. Some of them are very original while others are best forgotten.<br /><br />He depicts postwar Germany as a nightmarish train journey. With so many cities lying in ruins, Leo Kessler a young American of German descent feels obliged to help in their restoration. It is not a simple task as he quickly finds out.<br /><br />His uncle finds him a job as a night conductor on the Zentropa Railway Line. His job is to attend to the needs of the passengers. When the shoes are polished a chalk mark is made on the soles. A terrible argument ensues when a passenger's shoes are not chalked despite the fact they have been polished. There are many allusions to the German fanaticism of adherence to such stupid details.<br /><br />The railway journey is like an allegory representing man's procession through life with all its trials and tribulations. In one sequence Leo dashes through the back carriages to discover them filled with half-starved bodies appearing to have just escaped from Auschwitz . These images, horrible as they are, are fleeting as in a dream, each with its own terrible impact yet unconnected.<br /><br />At a station called Urmitz Leo jumps from the train with a parceled bomb. In view of many by-standers he connects the bomb to the underside of a carriage. He returns to his cabin and makes a connection to a time clock. Later he jumps from the train (at high speed) and lies in the cool grass on a river bank. Looking at the stars above he decides that his job is to build and not destroy. Subsequently as he sees the train approaching a giant bridge he runs at breakneck speed to board the train and stop the clock. If you care to analyse the situation it is a completely impossible task. Quite ridiculous in fact. It could only happen in a dream.<br /><br />It's strange how one remembers little details such as a row of cups hanging on hooks and rattling away with the swaying of the train.<br /><br />Despite the fact that this film is widely acclaimed, I prefer Lars Von Trier's later films (Breaking the Waves and The Idiots). The bomb scene described above really put me off. Perhaps I'm a realist.\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = dataset['text'].loc[2]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lars Von Trier is never backward in trying out new techniques. Some of them are very original while others are best forgotten.He depicts postwar Germany as a nightmarish train journey. With so many cities lying in ruins, Leo Kessler a young American of German descent feels obliged to help in their restoration. It is not a simple task as he quickly finds out.His uncle finds him a job as a night conductor on the Zentropa Railway Line. His job is to attend to the needs of the passengers. When the shoes are polished a chalk mark is made on the soles. A terrible argument ensues when a passenger's shoes are not chalked despite the fact they have been polished. There are many allusions to the German fanaticism of adherence to such stupid details.The railway journey is like an allegory representing man's procession through life with all its trials and tribulations. In one sequence Leo dashes through the back carriages to discover them filled with half-starved bodies appearing to have just escaped from Auschwitz . These images, horrible as they are, are fleeting as in a dream, each with its own terrible impact yet unconnected.At a station called Urmitz Leo jumps from the train with a parceled bomb. In view of many by-standers he connects the bomb to the underside of a carriage. He returns to his cabin and makes a connection to a time clock. Later he jumps from the train (at high speed) and lies in the cool grass on a river bank. Looking at the stars above he decides that his job is to build and not destroy. Subsequently as he sees the train approaching a giant bridge he runs at breakneck speed to board the train and stop the clock. If you care to analyse the situation it is a completely impossible task. Quite ridiculous in fact. It could only happen in a dream.It's strange how one remembers little details such as a row of cups hanging on hooks and rattling away with the swaying of the train.Despite the fact that this film is widely acclaimed, I prefer Lars Von Trier's later films (Breaking the Waves and The Idiots). The bomb scene described above really put me off. Perhaps I'm a realist.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the raw text data contains html script\n",
    "# So we need to remove html element and clean the data using html.parser from BeautifulSoup\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "#  remove http format and clean text\n",
    "soup = BeautifulSoup(review, \"html.parser\")\n",
    "review = soup.get_text()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lars von trier is never backward in trying out new techniques  some of them are very original while others are best forgotten he depicts postwar germany as a nightmarish train journey  with so many cities lying in ruins  leo kessler a young american of german descent feels obliged to help in their restoration  it is not a simple task as he quickly finds out his uncle finds him a job as a night conductor on the zentropa railway line  his job is to attend to the needs of the passengers  when the shoes are polished a chalk mark is made on the soles  a terrible argument ensues when a passenger s shoes are not chalked despite the fact they have been polished  there are many allusions to the german fanaticism of adherence to such stupid details the railway journey is like an allegory representing man s procession through life with all its trials and tribulations  in one sequence leo dashes through the back carriages to discover them filled with half starved bodies appearing to have just escaped from auschwitz   these images  horrible as they are  are fleeting as in a dream  each with its own terrible impact yet unconnected at a station called urmitz leo jumps from the train with a parceled bomb  in view of many by standers he connects the bomb to the underside of a carriage  he returns to his cabin and makes a connection to a time clock  later he jumps from the train  at high speed  and lies in the cool grass on a river bank  looking at the stars above he decides that his job is to build and not destroy  subsequently as he sees the train approaching a giant bridge he runs at breakneck speed to board the train and stop the clock  if you care to analyse the situation it is a completely impossible task  quite ridiculous in fact  it could only happen in a dream it s strange how one remembers little details such as a row of cups hanging on hooks and rattling away with the swaying of the train despite the fact that this film is widely acclaimed  i prefer lars von trier s later films  breaking the waves and the idiots   the bomb scene described above really put me off  perhaps i m a realist '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use re regular equation to convert text to lower case\n",
    "import re\n",
    "review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "review = review.lower()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 'is',\n",
       " 'never',\n",
       " 'backward',\n",
       " 'in',\n",
       " 'trying',\n",
       " 'out',\n",
       " 'new',\n",
       " 'techniques',\n",
       " 'some',\n",
       " 'of',\n",
       " 'them',\n",
       " 'are',\n",
       " 'very',\n",
       " 'original',\n",
       " 'while',\n",
       " 'others',\n",
       " 'are',\n",
       " 'best',\n",
       " 'forgotten',\n",
       " 'he',\n",
       " 'depicts',\n",
       " 'postwar',\n",
       " 'germany',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nightmarish',\n",
       " 'train',\n",
       " 'journey',\n",
       " 'with',\n",
       " 'so',\n",
       " 'many',\n",
       " 'cities',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'ruins',\n",
       " 'leo',\n",
       " 'kessler',\n",
       " 'a',\n",
       " 'young',\n",
       " 'american',\n",
       " 'of',\n",
       " 'german',\n",
       " 'descent',\n",
       " 'feels',\n",
       " 'obliged',\n",
       " 'to',\n",
       " 'help',\n",
       " 'in',\n",
       " 'their',\n",
       " 'restoration',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'simple',\n",
       " 'task',\n",
       " 'as',\n",
       " 'he',\n",
       " 'quickly',\n",
       " 'finds',\n",
       " 'out',\n",
       " 'his',\n",
       " 'uncle',\n",
       " 'finds',\n",
       " 'him',\n",
       " 'a',\n",
       " 'job',\n",
       " 'as',\n",
       " 'a',\n",
       " 'night',\n",
       " 'conductor',\n",
       " 'on',\n",
       " 'the',\n",
       " 'zentropa',\n",
       " 'railway',\n",
       " 'line',\n",
       " 'his',\n",
       " 'job',\n",
       " 'is',\n",
       " 'to',\n",
       " 'attend',\n",
       " 'to',\n",
       " 'the',\n",
       " 'needs',\n",
       " 'of',\n",
       " 'the',\n",
       " 'passengers',\n",
       " 'when',\n",
       " 'the',\n",
       " 'shoes',\n",
       " 'are',\n",
       " 'polished',\n",
       " 'a',\n",
       " 'chalk',\n",
       " 'mark',\n",
       " 'is',\n",
       " 'made',\n",
       " 'on',\n",
       " 'the',\n",
       " 'soles',\n",
       " 'a',\n",
       " 'terrible',\n",
       " 'argument',\n",
       " 'ensues',\n",
       " 'when',\n",
       " 'a',\n",
       " 'passenger',\n",
       " 's',\n",
       " 'shoes',\n",
       " 'are',\n",
       " 'not',\n",
       " 'chalked',\n",
       " 'despite',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'they',\n",
       " 'have',\n",
       " 'been',\n",
       " 'polished',\n",
       " 'there',\n",
       " 'are',\n",
       " 'many',\n",
       " 'allusions',\n",
       " 'to',\n",
       " 'the',\n",
       " 'german',\n",
       " 'fanaticism',\n",
       " 'of',\n",
       " 'adherence',\n",
       " 'to',\n",
       " 'such',\n",
       " 'stupid',\n",
       " 'details',\n",
       " 'the',\n",
       " 'railway',\n",
       " 'journey',\n",
       " 'is',\n",
       " 'like',\n",
       " 'an',\n",
       " 'allegory',\n",
       " 'representing',\n",
       " 'man',\n",
       " 's',\n",
       " 'procession',\n",
       " 'through',\n",
       " 'life',\n",
       " 'with',\n",
       " 'all',\n",
       " 'its',\n",
       " 'trials',\n",
       " 'and',\n",
       " 'tribulations',\n",
       " 'in',\n",
       " 'one',\n",
       " 'sequence',\n",
       " 'leo',\n",
       " 'dashes',\n",
       " 'through',\n",
       " 'the',\n",
       " 'back',\n",
       " 'carriages',\n",
       " 'to',\n",
       " 'discover',\n",
       " 'them',\n",
       " 'filled',\n",
       " 'with',\n",
       " 'half',\n",
       " 'starved',\n",
       " 'bodies',\n",
       " 'appearing',\n",
       " 'to',\n",
       " 'have',\n",
       " 'just',\n",
       " 'escaped',\n",
       " 'from',\n",
       " 'auschwitz',\n",
       " 'these',\n",
       " 'images',\n",
       " 'horrible',\n",
       " 'as',\n",
       " 'they',\n",
       " 'are',\n",
       " 'are',\n",
       " 'fleeting',\n",
       " 'as',\n",
       " 'in',\n",
       " 'a',\n",
       " 'dream',\n",
       " 'each',\n",
       " 'with',\n",
       " 'its',\n",
       " 'own',\n",
       " 'terrible',\n",
       " 'impact',\n",
       " 'yet',\n",
       " 'unconnected',\n",
       " 'at',\n",
       " 'a',\n",
       " 'station',\n",
       " 'called',\n",
       " 'urmitz',\n",
       " 'leo',\n",
       " 'jumps',\n",
       " 'from',\n",
       " 'the',\n",
       " 'train',\n",
       " 'with',\n",
       " 'a',\n",
       " 'parceled',\n",
       " 'bomb',\n",
       " 'in',\n",
       " 'view',\n",
       " 'of',\n",
       " 'many',\n",
       " 'by',\n",
       " 'standers',\n",
       " 'he',\n",
       " 'connects',\n",
       " 'the',\n",
       " 'bomb',\n",
       " 'to',\n",
       " 'the',\n",
       " 'underside',\n",
       " 'of',\n",
       " 'a',\n",
       " 'carriage',\n",
       " 'he',\n",
       " 'returns',\n",
       " 'to',\n",
       " 'his',\n",
       " 'cabin',\n",
       " 'and',\n",
       " 'makes',\n",
       " 'a',\n",
       " 'connection',\n",
       " 'to',\n",
       " 'a',\n",
       " 'time',\n",
       " 'clock',\n",
       " 'later',\n",
       " 'he',\n",
       " 'jumps',\n",
       " 'from',\n",
       " 'the',\n",
       " 'train',\n",
       " 'at',\n",
       " 'high',\n",
       " 'speed',\n",
       " 'and',\n",
       " 'lies',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cool',\n",
       " 'grass',\n",
       " 'on',\n",
       " 'a',\n",
       " 'river',\n",
       " 'bank',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'above',\n",
       " 'he',\n",
       " 'decides',\n",
       " 'that',\n",
       " 'his',\n",
       " 'job',\n",
       " 'is',\n",
       " 'to',\n",
       " 'build',\n",
       " 'and',\n",
       " 'not',\n",
       " 'destroy',\n",
       " 'subsequently',\n",
       " 'as',\n",
       " 'he',\n",
       " 'sees',\n",
       " 'the',\n",
       " 'train',\n",
       " 'approaching',\n",
       " 'a',\n",
       " 'giant',\n",
       " 'bridge',\n",
       " 'he',\n",
       " 'runs',\n",
       " 'at',\n",
       " 'breakneck',\n",
       " 'speed',\n",
       " 'to',\n",
       " 'board',\n",
       " 'the',\n",
       " 'train',\n",
       " 'and',\n",
       " 'stop',\n",
       " 'the',\n",
       " 'clock',\n",
       " 'if',\n",
       " 'you',\n",
       " 'care',\n",
       " 'to',\n",
       " 'analyse',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'completely',\n",
       " 'impossible',\n",
       " 'task',\n",
       " 'quite',\n",
       " 'ridiculous',\n",
       " 'in',\n",
       " 'fact',\n",
       " 'it',\n",
       " 'could',\n",
       " 'only',\n",
       " 'happen',\n",
       " 'in',\n",
       " 'a',\n",
       " 'dream',\n",
       " 'it',\n",
       " 's',\n",
       " 'strange',\n",
       " 'how',\n",
       " 'one',\n",
       " 'remembers',\n",
       " 'little',\n",
       " 'details',\n",
       " 'such',\n",
       " 'as',\n",
       " 'a',\n",
       " 'row',\n",
       " 'of',\n",
       " 'cups',\n",
       " 'hanging',\n",
       " 'on',\n",
       " 'hooks',\n",
       " 'and',\n",
       " 'rattling',\n",
       " 'away',\n",
       " 'with',\n",
       " 'the',\n",
       " 'swaying',\n",
       " 'of',\n",
       " 'the',\n",
       " 'train',\n",
       " 'despite',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'this',\n",
       " 'film',\n",
       " 'is',\n",
       " 'widely',\n",
       " 'acclaimed',\n",
       " 'i',\n",
       " 'prefer',\n",
       " 'lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 's',\n",
       " 'later',\n",
       " 'films',\n",
       " 'breaking',\n",
       " 'the',\n",
       " 'waves',\n",
       " 'and',\n",
       " 'the',\n",
       " 'idiots',\n",
       " 'the',\n",
       " 'bomb',\n",
       " 'scene',\n",
       " 'described',\n",
       " 'above',\n",
       " 'really',\n",
       " 'put',\n",
       " 'me',\n",
       " 'off',\n",
       " 'perhaps',\n",
       " 'i',\n",
       " 'm',\n",
       " 'a',\n",
       " 'realist']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.split()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/wenkanw/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 'never',\n",
       " 'backward',\n",
       " 'trying',\n",
       " 'new',\n",
       " 'techniques',\n",
       " 'original',\n",
       " 'others',\n",
       " 'best',\n",
       " 'forgotten',\n",
       " 'depicts',\n",
       " 'postwar',\n",
       " 'germany',\n",
       " 'nightmarish',\n",
       " 'train',\n",
       " 'journey',\n",
       " 'many',\n",
       " 'cities',\n",
       " 'lying',\n",
       " 'ruins',\n",
       " 'leo',\n",
       " 'kessler',\n",
       " 'young',\n",
       " 'american',\n",
       " 'german',\n",
       " 'descent',\n",
       " 'feels',\n",
       " 'obliged',\n",
       " 'help',\n",
       " 'restoration',\n",
       " 'simple',\n",
       " 'task',\n",
       " 'quickly',\n",
       " 'finds',\n",
       " 'uncle',\n",
       " 'finds',\n",
       " 'job',\n",
       " 'night',\n",
       " 'conductor',\n",
       " 'zentropa',\n",
       " 'railway',\n",
       " 'line',\n",
       " 'job',\n",
       " 'attend',\n",
       " 'needs',\n",
       " 'passengers',\n",
       " 'shoes',\n",
       " 'polished',\n",
       " 'chalk',\n",
       " 'mark',\n",
       " 'made',\n",
       " 'soles',\n",
       " 'terrible',\n",
       " 'argument',\n",
       " 'ensues',\n",
       " 'passenger',\n",
       " 'shoes',\n",
       " 'chalked',\n",
       " 'despite',\n",
       " 'fact',\n",
       " 'polished',\n",
       " 'many',\n",
       " 'allusions',\n",
       " 'german',\n",
       " 'fanaticism',\n",
       " 'adherence',\n",
       " 'stupid',\n",
       " 'details',\n",
       " 'railway',\n",
       " 'journey',\n",
       " 'like',\n",
       " 'allegory',\n",
       " 'representing',\n",
       " 'man',\n",
       " 'procession',\n",
       " 'life',\n",
       " 'trials',\n",
       " 'tribulations',\n",
       " 'one',\n",
       " 'sequence',\n",
       " 'leo',\n",
       " 'dashes',\n",
       " 'back',\n",
       " 'carriages',\n",
       " 'discover',\n",
       " 'filled',\n",
       " 'half',\n",
       " 'starved',\n",
       " 'bodies',\n",
       " 'appearing',\n",
       " 'escaped',\n",
       " 'auschwitz',\n",
       " 'images',\n",
       " 'horrible',\n",
       " 'fleeting',\n",
       " 'dream',\n",
       " 'terrible',\n",
       " 'impact',\n",
       " 'yet',\n",
       " 'unconnected',\n",
       " 'station',\n",
       " 'called',\n",
       " 'urmitz',\n",
       " 'leo',\n",
       " 'jumps',\n",
       " 'train',\n",
       " 'parceled',\n",
       " 'bomb',\n",
       " 'view',\n",
       " 'many',\n",
       " 'standers',\n",
       " 'connects',\n",
       " 'bomb',\n",
       " 'underside',\n",
       " 'carriage',\n",
       " 'returns',\n",
       " 'cabin',\n",
       " 'makes',\n",
       " 'connection',\n",
       " 'time',\n",
       " 'clock',\n",
       " 'later',\n",
       " 'jumps',\n",
       " 'train',\n",
       " 'high',\n",
       " 'speed',\n",
       " 'lies',\n",
       " 'cool',\n",
       " 'grass',\n",
       " 'river',\n",
       " 'bank',\n",
       " 'looking',\n",
       " 'stars',\n",
       " 'decides',\n",
       " 'job',\n",
       " 'build',\n",
       " 'destroy',\n",
       " 'subsequently',\n",
       " 'sees',\n",
       " 'train',\n",
       " 'approaching',\n",
       " 'giant',\n",
       " 'bridge',\n",
       " 'runs',\n",
       " 'breakneck',\n",
       " 'speed',\n",
       " 'board',\n",
       " 'train',\n",
       " 'stop',\n",
       " 'clock',\n",
       " 'care',\n",
       " 'analyse',\n",
       " 'situation',\n",
       " 'completely',\n",
       " 'impossible',\n",
       " 'task',\n",
       " 'quite',\n",
       " 'ridiculous',\n",
       " 'fact',\n",
       " 'could',\n",
       " 'happen',\n",
       " 'dream',\n",
       " 'strange',\n",
       " 'one',\n",
       " 'remembers',\n",
       " 'little',\n",
       " 'details',\n",
       " 'row',\n",
       " 'cups',\n",
       " 'hanging',\n",
       " 'hooks',\n",
       " 'rattling',\n",
       " 'away',\n",
       " 'swaying',\n",
       " 'train',\n",
       " 'despite',\n",
       " 'fact',\n",
       " 'film',\n",
       " 'widely',\n",
       " 'acclaimed',\n",
       " 'prefer',\n",
       " 'lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 'later',\n",
       " 'films',\n",
       " 'breaking',\n",
       " 'waves',\n",
       " 'idiots',\n",
       " 'bomb',\n",
       " 'scene',\n",
       " 'described',\n",
       " 'really',\n",
       " 'put',\n",
       " 'perhaps',\n",
       " 'realist']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#remove stop words here since stop words don't contain information related to sentiment / rating \n",
    "review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 'never',\n",
       " 'backward',\n",
       " 'trying',\n",
       " 'new',\n",
       " 'technique',\n",
       " 'original',\n",
       " 'others',\n",
       " 'best',\n",
       " 'forgotten',\n",
       " 'depicts',\n",
       " 'postwar',\n",
       " 'germany',\n",
       " 'nightmarish',\n",
       " 'train',\n",
       " 'journey',\n",
       " 'many',\n",
       " 'city',\n",
       " 'lying',\n",
       " 'ruin',\n",
       " 'leo',\n",
       " 'kessler',\n",
       " 'young',\n",
       " 'american',\n",
       " 'german',\n",
       " 'descent',\n",
       " 'feel',\n",
       " 'obliged',\n",
       " 'help',\n",
       " 'restoration',\n",
       " 'simple',\n",
       " 'task',\n",
       " 'quickly',\n",
       " 'find',\n",
       " 'uncle',\n",
       " 'find',\n",
       " 'job',\n",
       " 'night',\n",
       " 'conductor',\n",
       " 'zentropa',\n",
       " 'railway',\n",
       " 'line',\n",
       " 'job',\n",
       " 'attend',\n",
       " 'need',\n",
       " 'passenger',\n",
       " 'shoe',\n",
       " 'polished',\n",
       " 'chalk',\n",
       " 'mark',\n",
       " 'made',\n",
       " 'sol',\n",
       " 'terrible',\n",
       " 'argument',\n",
       " 'ensues',\n",
       " 'passenger',\n",
       " 'shoe',\n",
       " 'chalked',\n",
       " 'despite',\n",
       " 'fact',\n",
       " 'polished',\n",
       " 'many',\n",
       " 'allusion',\n",
       " 'german',\n",
       " 'fanaticism',\n",
       " 'adherence',\n",
       " 'stupid',\n",
       " 'detail',\n",
       " 'railway',\n",
       " 'journey',\n",
       " 'like',\n",
       " 'allegory',\n",
       " 'representing',\n",
       " 'man',\n",
       " 'procession',\n",
       " 'life',\n",
       " 'trial',\n",
       " 'tribulation',\n",
       " 'one',\n",
       " 'sequence',\n",
       " 'leo',\n",
       " 'dash',\n",
       " 'back',\n",
       " 'carriage',\n",
       " 'discover',\n",
       " 'filled',\n",
       " 'half',\n",
       " 'starved',\n",
       " 'body',\n",
       " 'appearing',\n",
       " 'escaped',\n",
       " 'auschwitz',\n",
       " 'image',\n",
       " 'horrible',\n",
       " 'fleeting',\n",
       " 'dream',\n",
       " 'terrible',\n",
       " 'impact',\n",
       " 'yet',\n",
       " 'unconnected',\n",
       " 'station',\n",
       " 'called',\n",
       " 'urmitz',\n",
       " 'leo',\n",
       " 'jump',\n",
       " 'train',\n",
       " 'parceled',\n",
       " 'bomb',\n",
       " 'view',\n",
       " 'many',\n",
       " 'stander',\n",
       " 'connects',\n",
       " 'bomb',\n",
       " 'underside',\n",
       " 'carriage',\n",
       " 'return',\n",
       " 'cabin',\n",
       " 'make',\n",
       " 'connection',\n",
       " 'time',\n",
       " 'clock',\n",
       " 'later',\n",
       " 'jump',\n",
       " 'train',\n",
       " 'high',\n",
       " 'speed',\n",
       " 'lie',\n",
       " 'cool',\n",
       " 'grass',\n",
       " 'river',\n",
       " 'bank',\n",
       " 'looking',\n",
       " 'star',\n",
       " 'decides',\n",
       " 'job',\n",
       " 'build',\n",
       " 'destroy',\n",
       " 'subsequently',\n",
       " 'see',\n",
       " 'train',\n",
       " 'approaching',\n",
       " 'giant',\n",
       " 'bridge',\n",
       " 'run',\n",
       " 'breakneck',\n",
       " 'speed',\n",
       " 'board',\n",
       " 'train',\n",
       " 'stop',\n",
       " 'clock',\n",
       " 'care',\n",
       " 'analyse',\n",
       " 'situation',\n",
       " 'completely',\n",
       " 'impossible',\n",
       " 'task',\n",
       " 'quite',\n",
       " 'ridiculous',\n",
       " 'fact',\n",
       " 'could',\n",
       " 'happen',\n",
       " 'dream',\n",
       " 'strange',\n",
       " 'one',\n",
       " 'remembers',\n",
       " 'little',\n",
       " 'detail',\n",
       " 'row',\n",
       " 'cup',\n",
       " 'hanging',\n",
       " 'hook',\n",
       " 'rattling',\n",
       " 'away',\n",
       " 'swaying',\n",
       " 'train',\n",
       " 'despite',\n",
       " 'fact',\n",
       " 'film',\n",
       " 'widely',\n",
       " 'acclaimed',\n",
       " 'prefer',\n",
       " 'lars',\n",
       " 'von',\n",
       " 'trier',\n",
       " 'later',\n",
       " 'film',\n",
       " 'breaking',\n",
       " 'wave',\n",
       " 'idiot',\n",
       " 'bomb',\n",
       " 'scene',\n",
       " 'described',\n",
       " 'really',\n",
       " 'put',\n",
       " 'perhaps',\n",
       " 'realist']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# lemmatizer words, re-form the distorted words\n",
    "\n",
    "# if use stemmer, deannotate the following line. But Lemmatizer is better than stemmer\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "lem = WordNetLemmatizer()\n",
    "review = [lem.lemmatize(word) for word in review]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lars von trier never backward trying new technique original others best forgotten depicts postwar germany nightmarish train journey many city lying ruin leo kessler young american german descent feel obliged help restoration simple task quickly find uncle find job night conductor zentropa railway line job attend need passenger shoe polished chalk mark made sol terrible argument ensues passenger shoe chalked despite fact polished many allusion german fanaticism adherence stupid detail railway journey like allegory representing man procession life trial tribulation one sequence leo dash back carriage discover filled half starved body appearing escaped auschwitz image horrible fleeting dream terrible impact yet unconnected station called urmitz leo jump train parceled bomb view many stander connects bomb underside carriage return cabin make connection time clock later jump train high speed lie cool grass river bank looking star decides job build destroy subsequently see train approaching giant bridge run breakneck speed board train stop clock care analyse situation completely impossible task quite ridiculous fact could happen dream strange one remembers little detail row cup hanging hook rattling away swaying train despite fact film widely acclaimed prefer lars von trier later film breaking wave idiot bomb scene described really put perhaps realist'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1,\n",
       "        1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "        1, 2, 1, 2, 1, 1, 3, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 1, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "        1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 6, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "        1, 2, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with count vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# count_vec= CountVectorizer(binary=True)  #convert count to binary 0 1 values\n",
    "count_vec= CountVectorizer()\n",
    "review_count_vec= count_vec.fit_transform(corpus)\n",
    "review_count_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.1726306 , 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.11508707, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.11508707, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.11508707, 0.05754353,\n",
       "        0.11508707, 0.05754353, 0.11508707, 0.05754353, 0.05754353,\n",
       "        0.1726306 , 0.05754353, 0.05754353, 0.05754353, 0.11508707,\n",
       "        0.11508707, 0.05754353, 0.05754353, 0.11508707, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.1726306 , 0.11508707,\n",
       "        0.11508707, 0.05754353, 0.11508707, 0.11508707, 0.1726306 ,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.1726306 , 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.11508707, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.11508707, 0.05754353, 0.11508707,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.11508707, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.11508707, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.11508707, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353, 0.11508707, 0.05754353, 0.11508707, 0.05754353,\n",
       "        0.3452612 , 0.05754353, 0.05754353, 0.11508707, 0.05754353,\n",
       "        0.05754353, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.11508707, 0.05754353, 0.05754353, 0.05754353, 0.05754353,\n",
       "        0.05754353]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with TFIDF vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "review_tfidf_vec = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "review_tfidf_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_train = dataset['text']\n",
    "train_data_label = dataset['label']\n",
    "testdata = pd.read_csv(\"../aclImdb/test.csv\")\n",
    "dataset_test= testdata['text']\n",
    "test_data_label = testdata['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_label.shape, train_data_label.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Previous reviewer Claudio Carvalho gave a much better recap of the film's plot details than I could. What I recall mostly is that it was just so beautiful, in every sense - emotionally, visually, editorially - just gorgeous.<br /><br />If you like movies that are wonderful to look at, and also have emotional content to which that beauty is relevant, I think you will be glad to have seen this extraordinary and unusual work of art.<br /><br />On a scale of 1 to 10, I'd give it about an 8.75. The only reason I shy away from 9 is that it is a mood piece. If you are in the mood for a really artistic, very romantic film, then it's a 10. I definitely think it's a must-see, but none of us can be in that mood all the time, so, overall, 8.75.\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postwar Europe. Like TTM, there is much inventive camera work. There is an innocent American who gets emotionally involved with a woman he doesn\\'t really understand, and whose naivety is all the more striking in contrast with the natives.<br /><br />But I\\'d have to say that The Third Man has a more well-crafted storyline. Zentropa is a bit disjointed in this respect. Perhaps this is intentional: it is presented as a dream/nightmare, and making it too coherent would spoil the effect. <br /><br />This movie is unrelentingly grim--\"noir\" in more than one sense; one never sees the sun shine. Grim, but intriguing, and frightening.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv(\"../aclImdb/test.csv\")\n",
    "dataset_test= testdata['text']\n",
    "test_data_label = testdata['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text here\n",
    "Since there are some text in html format and some distorted text, we need to clean and restore text by using BeautifulSoup(clean html text)  and NLTK,Lemmatizer (restore text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/wenkanw/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def clean_data(dataset):\n",
    "    corpus_data= []\n",
    "    for i in range(dataset.shape[0]):\n",
    "        soup = BeautifulSoup(dataset.iloc[i], \"html.parser\")\n",
    "        review = soup.get_text()\n",
    "        review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "        review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        # remove stopwords\n",
    "        review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "        # lemmatize the distorted words\n",
    "        lem = WordNetLemmatizer()\n",
    "        review = [lem.lemmatize(word) for word in review]\n",
    "        review = ' '.join(review)\n",
    "        # cleaned text data\n",
    "        corpus_data.append(review)\n",
    "    return corpus_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_train = clean_data(dataset_train)\n",
    "# corpus_test = clean_data(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'previous reviewer claudio carvalho gave much better recap film plot detail could recall mostly beautiful every sense emotionally visually editorially gorgeous like movie wonderful look also emotional content beauty relevant think glad seen extraordinary unusual work art scale give reason shy away mood piece mood really artistic romantic film definitely think must see none u mood time overall'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def save_clean_data(train_txt, train_label,train_score, test_txt,test_label,test_score):\n",
    "    fp = open(\"cleaned_train.csv\",\"w+\")\n",
    "    fieldnames = [\"text\",\"label\",\"score\"]\n",
    "    writer = csv.DictWriter(fp, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(train_txt)):\n",
    "        writer.writerow({'text': train_txt[i], 'label': train_label[i],'score':train_score[i]})\n",
    "    fp.close()\n",
    "    \n",
    "    test_fp = open(\"cleaned_test.csv\",\"w+\")\n",
    "    fieldnames = [\"text\",\"label\",\"score\"]\n",
    "    writer = csv.DictWriter(test_fp, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(test_txt)):\n",
    "        \n",
    "        writer.writerow({'text': test_txt[i], 'label': test_label[i],'score':test_score[i]})\n",
    "    test_fp.close()\n",
    "\n",
    "def save_test_data( test_txt,test_label,test_score):\n",
    "    test_fp = open(\"cleaned_test.csv\",\"w+\")\n",
    "    fieldnames = [\"text\",\"label\",\"score\"]\n",
    "    writer = csv.DictWriter(test_fp, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(test_txt)):\n",
    "        writer.writerow({'text': test_txt[i], 'label': test_label[i],'score':test_score[i]})\n",
    "    test_fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_test_data(corpus_test, testdata['label'],testdata['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save cleaned text data for future use\n",
    "# save_clean_data(corpus_train,dataset['label'],dataset['score'],corpus_test, testdata['label'],testdata['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cleaned text data here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text dataset  that have been cleaned\n",
    "\n",
    "clean_data = pd.read_csv(\"cleaned_train.csv\")\n",
    "clean_test = pd.read_csv(\"cleaned_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test = clean_test['text']\n",
    "corpus_train = clean_data['text']\n",
    "len(clean_data),len(clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'film begin cowhand shagging female calf promise much stereotyping kibbutz yr ago well like ok every kibbutz small piece something shown film like youngster raiding kitchen night show whole kibbutz full shall say naughty trait kibbutz problem hardly kibbutz view israel great still remember youth garden eden called emek valley yes acting good see black wrong portrayal probably purpose'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['text'].iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wild rebel probably fun second film drive movie triple feature year ago aged well never meant age well obviously intended disposable forgettable fun inception taken level good example biker flick genre several element help distinguish dozen similar film churned time hero rod tillman steve alaimo come somewhat unimpressive everyman especially brave tough talented handsome although win fight tough biker gang member halfway film girl gang member chooses help fellow gang member end film soundtrack quite well done featuring nice venture style bass drum riff keep thing moving saxophone brass chart pep thing quite bit although script pretty shallow actor inhabit cardboard character convincingly fair amount energy plenty careless technical gaffe terrible day night scene occur broad daylight squealing tire swamp fire siren mistakenly stuck soundtrack instead police siren bank sign made duct tape ceiling tile luger sound like winchester shotgun blast cut people yard away detective killing biker rd floor landing ground revolver inch barrel whole bunch goofy story element linda girl gang member disables bank guard drug filled syringe final shootout take place inside lighthouse police roadblock actually block road police apparently never heard ducking police detective apparently never heard planting bug undercover guy wearing wire plot chug along cameraman know pacing scene pretty good nice zippy one liner dialog exchange keep energy level favorite man messing private stock ie linda seek one anything copy mst version fall hand good shallow fun watching vastly superior five hard way hellcat even girl gold boot three mst covered counter culture movie'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test['text'].iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Vectorize \n",
    "Convert raw text to vector (like Bag-of-word model, word2vector, fasttext, Glove) to  visualize and analyze text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Using TFIDF\n",
    "# n_gram: the number of char in a word\n",
    "# if using n_gram=3, then in [\"I Like dog so much\"] sentence, it is broken into [\"I like dog\", \"like dog so\", \"dog so much\"]\n",
    "# gram means the size of window that contains consecutive words\n",
    "\n",
    "#Note: Tfidf vectorizer already normalize the data and avoid zero-division by setting flag:  smooth_idf=True\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tfidf_vec_train = tfidf_vec.fit_transform(corpus_train)\n",
    "tfidf_vec_test = tfidf_vec.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Using count vectorizer\n",
    "count_vec = CountVectorizer(ngram_range=(1, 3), binary=False)\n",
    "count_vec_train = count_vec.fit_transform(corpus_train)\n",
    "count_vec_test = count_vec.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8202611, 8202611)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(tfidf_vec_train.data),len(count_vec_train.data)\n",
    "# la = np.linalg\n",
    "# U,s, Vp = la.svd(count_vec_train,full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 4485967), (25000, 4485967))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec_train.shape, tfidf_vec_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# vaderSentiment: a lexicon and rule-based tool\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simply Apply SentimentIntensityAnalyzer to see if it helps with classification of emotion\n",
    "\n",
    "sentimentIntensityAnalyzer is a lexicon and rule-based sentiment analysis tool. It measures the polarity score based on vocabulary meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentiment = clean_data.copy()\n",
    "sia=  SentimentIntensityAnalyzer()\n",
    "sentiment['polarity_score']=sentiment.text.apply(lambda x:sia.polarity_scores(x)['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.8715</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.9839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.3472</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.0064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.9854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9260</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  polarity_score Rating\n",
       "0          7         -0.0772      4\n",
       "1         10          0.8715     10\n",
       "2          7         -0.9839      1\n",
       "3         10         -0.3472      3\n",
       "4         10          0.9850     10\n",
       "...      ...             ...    ...\n",
       "24995      3         -0.0064      4\n",
       "24996      1         -0.9854      1\n",
       "24997      4          0.9789     10\n",
       "24998      1          0.9260     10\n",
       "24999      3          0.9491     10\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step: -1.0  -0.75, -0.5, -0.25,  0, 0.25,  0.5, 0.75,   1\n",
    "#Rating:     1      2     3     4    7      8    9     10   \n",
    "step=0.25\n",
    "labels= [1,2,3,4,7,8,9,10]\n",
    "for i in range(8):\n",
    "    sentiment.loc[sentiment.polarity_score>=(step*i)-1.0,\"Rating\"]=labels[i]\n",
    "sentiment[['score','polarity_score','Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25752\n"
     ]
    }
   ],
   "source": [
    "# Accuracy when using SentimentIntensityAnalyzer\n",
    "print(\"Accuracy:\",len(sentiment.loc[sentiment.score==sentiment.Rating])/len(sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'film begin cowhand shagging female calf promise much stereotyping kibbutz yr ago well like ok every kibbutz small piece something shown film like youngster raiding kitchen night show whole kibbutz full shall say naughty trait kibbutz problem hardly kibbutz view israel great still remember youth garden eden called emek valley yes acting good see black wrong portrayal probably purpose'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment['text'].iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Any film which begins with a cowhand shagging a female calf can't promise much. As for the stereotyping of the kibbutz as it was 50 yrs ago, well I was there and it just wasn't like that. OK every kibbutz had just a small piece of something shown in the film (like youngsters raiding the kitchen at night) but you can't show the whole kibbutz as being full of all those - shall we say - naughty traits. Each kibbutz had its own problems, but hardly any kibbutz had all of them. The views of Israel were great. I still remember my youth in that Garden of Eden called the Emek (valley). Yes, and the acting was good too, so you see it wasn't all black - just a wrong portrayal - probably on purpose too.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'].iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords.words('english')\n",
    "\n",
    "not_words= ['don',\n",
    " \"don't\",\n",
    " 'should',\n",
    " \"should've\",\n",
    " 'aren',\n",
    " \"aren't\",\n",
    " 'couldn',\n",
    " \"couldn't\",\n",
    " 'didn',\n",
    " \"didn't\",\n",
    " 'doesn',\n",
    " \"doesn't\",\n",
    " 'hadn',\n",
    " \"hadn't\",\n",
    " 'hasn',\n",
    " \"hasn't\",\n",
    " 'haven',\n",
    " \"haven't\",\n",
    " 'isn',\n",
    " \"isn't\",\n",
    " 'mightn',\n",
    " \"mightn't\",\n",
    " 'mustn',\n",
    " \"mustn't\",\n",
    " 'needn',\n",
    " \"needn't\",\n",
    " 'shan',\n",
    " \"shan't\",\n",
    " 'shouldn',\n",
    " \"shouldn't\",\n",
    " 'wasn',\n",
    " \"wasn't\",\n",
    " 'weren',\n",
    " \"weren't\",\n",
    " 'won',\n",
    " \"won't\",\n",
    " 'wouldn',\n",
    " \"wouldn't\"]\n",
    "len(not_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of using sentimentIntensityAnalyzer (SIA)\n",
    "We can see the result is bad using SIA, possible reasons are following\n",
    "1. It is based on words from dictionary and hence ignores the context of words\n",
    "2. In text sentiment['text'].iloc[-2], we can see most of words are positive after removing stopwords.\n",
    "However, when looking at the original text, we can see stopword ,like can't, shouldn't, ahead the positive texts are removed. __Then the meaning of text is actually reversed and distorted after removing some stopwords!__. \n",
    "This could be a reason why the rating =1, but the polarity score is 0.9->rating=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Word2Vector and PCA for dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'concate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-10da0b1144b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorpuses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcorpuses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpuses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'concate'"
     ]
    }
   ],
   "source": [
    "# Test with Word2Vec model for word vectors\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "print(common_texts)\n",
    "corpuses = corpus_train.copy()\n",
    "corpuses += corpus_test\n",
    "model = Word2Vec(corpuses, size=100, window=5, min_count=1, workers=4)\n",
    "word_vectors = model.wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lars von trier never backward trying new technique original others best forgotten depicts postwar germany nightmarish train journey many city lying ruin leo kessler young american german descent feel obliged help restoration simple task quickly find uncle find job night conductor zentropa railway line job attend need passenger shoe polished chalk mark made sol terrible argument ensues passenger shoe chalked despite fact polished many allusion german fanaticism adherence stupid detail railway journey like allegory representing man procession life trial tribulation one sequence leo dash back carriage discover filled half starved body appearing escaped auschwitz image horrible fleeting dream terrible impact yet unconnected station called urmitz leo jump train parceled bomb view many stander connects bomb underside carriage return cabin make connection time clock later jump train high speed lie cool grass river bank looking star decides job build destroy subsequently see train approaching giant bridge run breakneck speed board train stop clock care analyse situation completely impossible task quite ridiculous fact could happen dream strange one remembers little detail row cup hanging hook rattling away swaying train despite fact film widely acclaimed prefer lars von trier later film breaking wave idiot bomb scene described really put perhaps realistfirst deepa mehta film saw film tv hindi version sita character presented nita also note radha underwent allegorical trial fire film nita sita yet loved film screenplay m mehta direction character big small well developed seemed quixotic towards end somewhat like end mazursky unmarried woman brave woman surrounded cardboard men one cardboard man ashok seems come alive last shot see carrying invalid mother biji seems finally take future responsibility beyond celibacy adherance religion m mehta seems fumble director however compared indian mainstream cinema would seem brilliant cannot use script go beyond microscopic joint family presenting except presenting glimpse chinese micro minority social milieu india even dedicates film mother daughter father yet radha reminesces halcyon day parent mustard field compare mrinal sen adoor gopalakrishnan muzaffar ali dwarfed giant given competent canadian production team financial resource mehta film two bisexual lady indian middle class household may sacrilege merely capture atrophy middle class home seem aspire something better immediate survival limited social space kannada malayalam bengali film touched parallel theme india publicity surrounded film therefore seen wide segment knowledgeable cinemagoers m da m azmi mr jafri mr kharbanda credible outstanding m azmi talented actress gave superb performance good director mrinal sen khandar gautam ghose paar benegal ankur brilliance notably absent film m da sparkled due screen presence rather acting capability film strength remains structure screenplay average term international cinema sure m mehta hone writing talent future screenplay\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained word-vectors from gensim-data\n",
    "\n",
    "# import gensim.downloader as api\n",
    "# glove_word_vectors = api.load(\"glove-wiki-gigaword-100\")  \n",
    "# result = glove_word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "# print(\"{}: {:.4f}\".format(*result[0]))\n",
    "\n",
    "\n",
    "# result = word_vectors.most_similar(positive=['like', 'enjoy'], negative=['sad'])\n",
    "# print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22, 'Yo': 23, 'si': 24, 'on': 25}\n",
      "Parameter containing:\n",
      "tensor([[ 0.0575, -0.1513,  0.1328,  0.1744, -0.0264,  0.1678, -0.1648, -0.0646,\n",
      "         -0.1617, -0.1345,  0.1446, -0.1234, -0.0837, -0.1888, -0.0679, -0.0176,\n",
      "          0.0958, -0.0148,  0.1158, -0.0202, -0.1049, -0.0290, -0.1068, -0.1386,\n",
      "         -0.0886,  0.0586],\n",
      "        [ 0.0372,  0.1108,  0.0497, -0.1885, -0.0363, -0.0570,  0.1852,  0.0322,\n",
      "         -0.0567,  0.1407, -0.0993,  0.0212,  0.1664,  0.0115, -0.1285,  0.1217,\n",
      "         -0.1870,  0.0233,  0.0737,  0.1719, -0.0487, -0.1668, -0.1702, -0.0219,\n",
      "         -0.0996, -0.0599]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0720, 0.0341], requires_grad=True)\n",
      "tensor([[-0.4829, -0.9597]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "        (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "        (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "        (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
    "\n",
    "test_data = [(\"Yo creo que si\".split(), \"SPANISH\"),\n",
    "             (\"it is lost on me\".split(), \"ENGLISH\")]\n",
    "\n",
    "# word_to_ix maps each word in the vocab to a unique integer, which will be its\n",
    "# index into the Bag of words vector\n",
    "word_to_ix = {}\n",
    "for sent, _ in data + test_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = 2\n",
    "\n",
    "\n",
    "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is vocab_size\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "\n",
    "\n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n",
    "\n",
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "\n",
    "# the model knows its parameters.  The first output below is A, the second is b.\n",
    "# Whenever you assign a component to a class variable in the __init__ function\n",
    "# of a module, which was done with the line\n",
    "# self.linear = nn.Linear(...)\n",
    "# Then through some Python magic from the PyTorch devs, your module\n",
    "# (in this case, BoWClassifier) will store knowledge of the nn.Linear's parameters\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "# To run the model, pass in a BoW vector\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    sample = data[0]\n",
    "    bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
    "    log_probs = model(bow_vector)\n",
    "    print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocab(vocab):\n",
    "    import csv\n",
    "    fp = open(\"vocab.csv\",\"w+\")\n",
    "    fieldname= [\"vocab\"]\n",
    "    writer = csv.DictWriter(fp, fieldnames= fieldname)\n",
    "    writer.writeheader()\n",
    "    for i in vocab:\n",
    "        writer.writerow({\"vocab\":i})\n",
    "    fp.close()\n",
    "    \n",
    "# compute vocabulary set\n",
    "vocab =set()\n",
    "for d in corpus_train:\n",
    "    vocab = vocab | set(d.split(\" \"))\n",
    "for d in corpus_test:\n",
    "    vocab = vocab |  set(d.split(\" \"))\n",
    "\n",
    "# save vocabulary \n",
    "save_vocab(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91721\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Word Embedding in pytorch\n",
    "#### Note 1: Usage of Word embedding in Pytorch is similar with that of Tensorflow\n",
    " Usage:\n",
    "  embed = Embedding(vocabulary_size, output_size, input_length)    # return an instance\n",
    "  one_hot_vector = one_hot(word, vocabulary size)\n",
    "  \n",
    "  \\# one_hot_vector here use index of word rather than 0,1 representation\n",
    "  word_vector = embed(one_hot_vector)   \n",
    "\n",
    "\n",
    "#### Note 2: \n",
    "     Since using word2vec, glove network to find word vector is a training process, \n",
    "     word embedding is actually a layer in the model you need to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4])\n",
      "tensor([[ 1.0892e+00,  1.2696e+00, -1.9310e-01,  3.5289e-01,  2.7012e-01,\n",
      "         -9.7955e-01, -1.2013e+00,  2.2520e-01, -2.7349e+00,  4.3028e-01,\n",
      "         -1.0089e-01,  5.5109e-01,  2.0240e-02, -2.9043e-01, -2.7021e-01,\n",
      "         -9.8227e-01,  1.7570e+00, -1.6500e+00,  1.0137e-01, -2.1284e-01,\n",
      "         -1.2893e-01,  1.1705e+00, -7.7892e-01, -1.5826e+00,  2.7917e-01,\n",
      "          1.6468e+00, -5.7773e-01,  4.2946e-01,  7.0890e-01,  7.3952e-01,\n",
      "         -7.3561e-01, -1.0517e+00, -9.0542e-01,  1.4862e+00, -1.2152e+00,\n",
      "          8.0583e-02, -5.6066e-01, -6.4583e-01,  2.6959e-01, -1.0710e+00,\n",
      "          1.2237e+00,  4.9748e-01, -1.2456e+00, -2.1904e+00,  1.5265e-01,\n",
      "         -1.9129e+00,  7.5209e-01,  2.5391e+00,  2.0054e+00,  4.7732e-01,\n",
      "         -6.5085e-01,  1.2591e+00,  6.3316e-01,  1.9343e+00, -8.0991e-01,\n",
      "         -1.2683e+00, -2.4974e-01, -1.5831e+00, -8.0501e-01,  2.7258e-01,\n",
      "          6.6800e-01, -1.0592e+00, -9.1319e-01,  7.0144e-01,  2.1859e-02,\n",
      "         -7.5321e-01, -6.4731e-02,  7.5385e-02, -8.6077e-01, -7.0217e-01,\n",
      "         -6.4292e-01,  1.2202e+00, -9.5975e-01, -6.1998e-01,  6.4554e-01,\n",
      "         -1.5891e+00, -1.7038e+00,  9.8506e-01, -7.7999e-01, -1.8039e+00,\n",
      "          4.0987e-01,  4.9854e-01, -3.5370e-01,  1.0017e-01,  3.8065e-02,\n",
      "          1.5503e+00, -7.5896e-01, -9.6619e-01,  6.0566e-01, -3.1831e-01,\n",
      "          1.0105e+00,  1.9924e-01, -1.8831e+00,  2.4242e+00, -7.1857e-01,\n",
      "          1.5586e+00, -9.3254e-02, -7.7582e-01,  1.0238e+00,  7.2597e-02,\n",
      "          7.6213e-01, -1.0408e-01, -1.7198e+00, -3.0475e-01,  1.8663e-01,\n",
      "         -9.2846e-01,  2.2990e+00,  9.7793e-01, -1.8355e+00, -4.9445e-01,\n",
      "         -1.5491e+00,  1.9726e-01, -9.1558e-01,  7.7403e-01,  9.2506e-01,\n",
      "          2.2289e-01, -2.6464e-01, -9.9222e-01, -3.5297e-01, -1.4421e+00,\n",
      "         -5.8576e-01,  2.8278e-01,  5.2674e-01,  9.6863e-01, -3.3360e-02,\n",
      "         -9.3225e-02,  7.9590e-02, -7.1471e-03,  2.8533e-01,  1.8252e+00,\n",
      "          7.5542e-01,  2.9547e-01, -5.6435e-01, -1.6912e+00, -7.6115e-02,\n",
      "         -9.0506e-01, -1.8347e+00, -2.2583e-01, -4.2692e-01, -3.7117e-01,\n",
      "         -6.5507e-01, -3.5417e-01,  5.0436e-01, -1.5931e+00,  1.9313e+00,\n",
      "         -1.5856e-01, -1.9179e-01,  1.0173e+00, -4.0324e-01,  3.3199e-01,\n",
      "         -9.6719e-01,  7.8870e-01, -1.1251e+00,  2.7634e-01, -6.7541e-01,\n",
      "         -1.3105e+00,  6.8660e-01, -4.4396e-01,  9.4488e-01,  1.0939e+00,\n",
      "         -1.4719e+00,  3.0138e-01,  1.5818e+00,  1.1508e-01,  5.2920e-01,\n",
      "          1.6868e-01,  8.4616e-01,  6.8521e-01,  1.6893e+00, -1.5373e-01,\n",
      "          1.4514e+00, -9.0905e-01, -2.0598e+00,  1.2508e+00, -5.6503e-01,\n",
      "          1.9137e+00, -4.4827e-01,  1.0039e+00, -9.9627e-02,  2.2940e-01,\n",
      "         -1.9814e-01, -1.1690e+00,  8.9522e-02, -8.0449e-01,  9.2960e-01,\n",
      "         -4.6208e-02,  1.7793e+00,  6.1602e-02,  5.9794e-01,  4.3362e-03,\n",
      "         -4.6554e-01,  2.8860e-01,  3.0946e-01, -1.6713e+00, -8.0960e-01,\n",
      "          8.3624e-01,  7.8083e-01,  1.6084e+00,  3.9399e-01,  1.3496e-01,\n",
      "         -4.4134e-01, -4.6013e-01,  5.5498e-01, -4.2641e-01,  1.7511e+00,\n",
      "         -9.5175e-01, -2.3162e+00,  7.5118e-02,  2.8044e-01, -4.8848e-01,\n",
      "          1.5393e+00, -9.8385e-01,  9.0963e-02,  3.5827e-01, -3.8863e-01,\n",
      "         -5.4623e-01, -4.4566e-01,  1.8751e+00,  7.8009e-01, -8.7713e-01,\n",
      "          1.2431e+00,  1.0001e+00,  2.4755e-01, -7.2771e-01, -1.5460e+00,\n",
      "          6.5783e-01, -5.9834e-01, -2.0652e+00, -7.8573e-01,  1.0290e+00,\n",
      "          1.2212e+00, -1.3505e+00,  1.3871e+00,  1.0777e+00, -6.0864e-01,\n",
      "          9.0893e-01, -4.8785e-01,  5.4707e-01,  3.8422e-02, -6.1498e-01,\n",
      "          5.2976e-01,  5.3856e-01,  1.2033e+00,  1.0898e+00,  6.6677e-01,\n",
      "          3.0267e-01, -6.5262e-01,  7.0128e-01, -9.5387e-01,  1.2788e-01,\n",
      "          9.6013e-02,  1.5187e-01,  1.5750e+00, -6.8112e-01, -1.7601e+00,\n",
      "         -2.6198e-01,  6.0285e-02,  4.4400e-01,  5.9820e-01, -1.0927e-01,\n",
      "         -1.7296e-01,  8.6733e-01,  7.1547e-01, -2.2410e+00, -3.1158e-01,\n",
      "         -1.2993e+00, -1.0054e+00, -1.4703e+00,  9.3889e-02,  9.3073e-01,\n",
      "          3.6045e-01,  8.5795e-02,  1.1316e+00, -1.0704e+00, -8.4116e-01,\n",
      "          3.3245e-01,  1.6834e+00, -5.5125e-01,  1.2632e+00,  1.3982e+00,\n",
      "          3.1669e-01, -1.5155e+00,  7.3882e-01,  2.6211e-01, -7.1546e-01,\n",
      "          4.0422e-01,  7.7117e-01,  8.2456e-01,  4.9499e-01,  1.3331e+00,\n",
      "          2.9996e-02,  2.6646e-01, -6.4850e-01,  9.2246e-01,  8.4077e-01,\n",
      "          6.9269e-02,  5.7638e-01,  1.1967e+00,  2.5858e+00, -2.3794e+00,\n",
      "         -2.5797e-01, -1.2375e+00,  1.2210e+00, -1.6574e+00,  1.1412e+00,\n",
      "          3.4199e-01,  3.6633e-01, -9.7451e-01, -7.1295e-01, -1.3116e+00,\n",
      "          1.9596e+00,  7.6088e-01, -2.8080e+00,  6.8914e-01, -7.2461e-01,\n",
      "          9.6466e-01,  8.0001e-01,  3.9075e-01, -1.5712e+00, -1.3702e-01,\n",
      "         -1.0659e+00,  6.3724e-01,  2.6581e-01,  8.4499e-02, -7.8196e-01,\n",
      "         -2.9411e-01,  4.8756e-01, -7.7608e-01, -8.1870e-01,  1.4812e+00,\n",
      "          5.2148e-03,  8.3858e-01,  1.5289e-01,  1.2087e+00,  1.4338e+00,\n",
      "         -8.8838e-01, -1.5347e+00, -1.5854e+00,  5.1880e-01, -2.0860e-01,\n",
      "         -5.9011e-01,  4.0406e-01,  1.1446e-02,  1.3932e+00, -8.0608e-01,\n",
      "         -1.5650e+00,  3.3399e-01,  2.6417e-01,  1.1201e+00,  3.8356e-01,\n",
      "         -2.2471e+00, -1.1476e+00,  1.6163e+00,  1.3232e+00, -4.6134e-01,\n",
      "         -8.6726e-02,  4.1587e-01, -1.5789e+00, -1.0352e+00, -9.3969e-01,\n",
      "          1.3407e+00,  1.2594e+00,  7.1250e-01, -1.8830e+00, -6.1366e-02,\n",
      "          5.8096e-01,  2.6272e-01,  5.8351e-01,  1.2669e+00,  1.2926e+00,\n",
      "         -1.2020e-01, -1.6747e+00,  1.4717e+00,  4.2368e-01,  6.6070e-01,\n",
      "         -3.2899e-01, -7.5733e-01,  8.6261e-01,  5.8135e-02,  6.8461e-01,\n",
      "          6.1319e-01,  2.6356e-01, -8.2823e-01,  1.2931e+00, -2.6591e+00,\n",
      "          5.6629e-01,  2.2321e-01,  4.8571e-02, -1.2127e+00, -1.5938e+00,\n",
      "         -6.6892e-02, -1.0103e+00, -1.4333e+00, -1.4637e+00, -1.7457e+00,\n",
      "          2.9294e-01, -8.1123e-01, -2.1017e+00,  9.5247e-01,  5.0183e-01,\n",
      "         -2.2411e+00, -5.7012e-02, -8.4495e-01,  4.3305e-01,  1.0752e+00,\n",
      "          1.1046e+00,  3.2101e-01, -8.7523e-01,  6.3320e-02, -6.2563e-02,\n",
      "          3.7273e-01,  1.6545e+00,  9.2091e-02, -1.1613e+00,  1.6723e+00,\n",
      "          9.6101e-01,  5.4513e-01,  1.0281e+00, -7.9534e-01,  2.1565e-01,\n",
      "         -4.4692e-01, -9.3307e-01, -4.1668e-02,  6.3820e-01, -1.4398e+00,\n",
      "          2.4137e-01,  9.1809e-01, -6.1002e-01, -8.8255e-01, -1.5378e+00,\n",
      "          7.4763e-01, -6.3611e-01, -7.1091e-01, -3.0457e-01, -3.2224e-01,\n",
      "         -4.6299e-01,  9.4512e-01, -6.9320e-01, -7.0735e-01,  7.1484e-01,\n",
      "         -2.3282e-01,  3.2835e-01, -4.6225e-01, -1.3003e+00,  1.7174e+00,\n",
      "          2.0096e+00,  2.2819e-01, -5.8640e-01,  9.2866e-01, -6.2601e-01,\n",
      "         -1.0647e+00,  1.0903e-02,  1.6172e+00,  1.6272e-01, -9.0241e-02,\n",
      "          7.0623e-02, -7.1298e-01,  1.3000e+00,  1.7950e+00,  1.4821e+00,\n",
      "          5.5573e-02, -3.7660e-01,  6.5358e-01, -7.5791e-01,  1.2615e-01,\n",
      "          8.1520e-01, -3.2719e-01,  8.3461e-01, -1.1189e+00, -1.8417e+00,\n",
      "          7.8846e-01,  2.2869e-01,  4.2726e-01, -7.1934e-01, -1.1834e+00,\n",
      "         -3.3462e-01,  9.0321e-01, -6.3922e-01, -2.3326e-02,  1.4046e+00,\n",
      "          1.3062e+00, -9.9713e-01, -6.7585e-01, -1.7687e+00,  1.5673e+00,\n",
      "         -4.3627e-01, -7.6656e-01,  3.1332e-02, -1.6408e+00, -7.5804e-01,\n",
      "         -1.5975e+00,  1.4641e+00,  1.4794e+00,  1.2419e+00, -4.2782e-01,\n",
      "          1.2538e-01,  5.2892e-01, -3.3900e-01,  3.0224e-02, -1.4166e+00,\n",
      "         -3.8384e-01,  2.9567e-01,  1.5863e-01, -3.9601e-01, -2.4600e-01,\n",
      "         -5.2526e-01, -7.9830e-01, -2.3962e-01, -1.1064e+00,  1.6579e-01,\n",
      "         -1.1707e-01, -9.4912e-01,  4.9306e-01, -1.7926e+00, -4.4107e-01,\n",
      "         -8.5749e-01, -1.1273e-01,  1.2155e+00, -9.4447e-01,  7.1482e-01,\n",
      "         -4.6001e-01,  2.7221e-01,  1.2479e+00,  1.9705e+00,  2.9647e-02,\n",
      "          4.8961e-01, -3.8866e-01,  8.2780e-02, -9.1585e-01,  5.2702e-01,\n",
      "         -2.9563e-01, -1.4803e+00,  7.0901e-01, -1.3735e-01, -6.4324e-01,\n",
      "         -2.7945e-01, -2.5624e-01,  2.2920e-01, -7.2982e-01, -1.1691e+00,\n",
      "          6.3079e-01, -3.2028e-01,  1.1507e+00,  2.2038e-01,  8.0448e-02,\n",
      "          1.5163e+00,  1.3921e+00, -6.8595e-03, -3.7997e-01,  9.5237e-01,\n",
      "          1.3514e+00,  5.0070e-01,  7.5206e-01,  1.3163e-02, -7.3721e-01,\n",
      "         -2.1535e+00,  4.2231e-01, -3.9265e-01, -2.9248e+00, -5.5301e-02,\n",
      "         -4.2033e-01, -4.6803e-02,  1.3504e+00,  4.8842e-01,  2.0448e-01,\n",
      "         -2.6685e+00,  9.2848e-01, -6.5839e-02,  4.7483e-01,  7.3294e-02,\n",
      "          1.3906e+00,  1.0163e-01,  4.2922e-01,  4.3274e-01, -1.8095e-01,\n",
      "         -9.9506e-01,  6.3259e-01,  7.1159e-01,  8.1137e-01, -8.6673e-01,\n",
      "          5.7226e-03, -8.0163e-01,  2.2255e-01, -4.0225e-01, -1.2106e-01,\n",
      "          7.4805e-01,  1.0482e-01,  1.5930e+00,  4.0887e-01, -7.6114e-01,\n",
      "          6.2149e-01,  3.3139e-01, -1.1213e-01, -2.8143e-01,  9.6847e-02,\n",
      "          5.8912e-02,  2.1689e-01, -2.6375e+00, -7.3608e-01,  7.1417e-01,\n",
      "         -9.6760e-01, -7.4010e-02, -6.0857e-02, -1.2999e-01, -2.7095e+00,\n",
      "          1.0476e+00, -1.0233e+00, -1.7440e-01, -2.9106e-01, -5.9101e-01,\n",
      "          1.4511e+00, -1.6667e+00, -1.9377e+00, -5.5868e-01, -5.3057e-01,\n",
      "          5.4240e-01, -5.8956e-01,  1.6451e-01,  9.7638e-01,  2.1245e-01,\n",
      "          1.0676e+00, -1.3846e+00, -3.6108e-01, -6.3676e-01,  1.1014e-01,\n",
      "          1.8180e+00, -9.9250e-01, -8.7424e-01,  1.1447e-01,  9.4756e-02,\n",
      "          2.6401e-01,  2.7114e+00, -1.7136e+00,  5.2563e-01,  8.3068e-01,\n",
      "          1.0137e+00,  6.3731e-01, -1.8361e-01, -7.6777e-01, -3.0876e-01,\n",
      "          1.0949e-01,  1.9332e+00, -1.1511e+00,  4.4689e-01, -1.0360e+00,\n",
      "         -1.6490e-02, -4.0645e-01,  8.2098e-02, -4.8016e-01, -4.2044e-01,\n",
      "         -1.1103e+00,  1.1401e+00,  1.3756e+00,  1.1285e+00,  1.7406e-01,\n",
      "          1.4863e+00,  7.5779e-02, -5.8173e-01, -8.9463e-02, -1.4434e+00,\n",
      "          3.8210e-01,  4.2211e-01,  1.3751e+00,  4.9090e-01, -1.1097e+00,\n",
      "          5.1637e-01, -2.7448e-01, -9.1037e-01, -9.6147e-01,  2.9480e-01,\n",
      "         -9.0251e-01, -6.8247e-01, -1.7155e-01, -5.4913e-01, -7.1046e-01,\n",
      "          1.8533e-02,  1.1857e+00, -8.7263e-01,  9.5932e-02,  2.7964e-01,\n",
      "         -8.5296e-01,  3.9908e-01, -7.1930e-01, -1.7806e+00,  4.5787e-01,\n",
      "         -1.4099e+00,  5.0453e-01, -8.8973e-01,  1.0467e+00,  1.0563e+00,\n",
      "         -7.7273e-01,  1.3910e-01,  2.0901e-01,  9.0334e-01,  2.3220e-01,\n",
      "          7.7652e-01,  7.4786e-01,  1.8066e-01, -1.4861e+00, -1.0330e+00,\n",
      "          2.4337e+00,  6.1558e-02, -1.1008e+00,  1.3637e+00,  1.7533e+00,\n",
      "         -6.7499e-01,  1.5962e-01, -8.3378e-01, -4.1466e-01,  6.3529e-01,\n",
      "         -7.1240e-01,  5.1198e-01,  1.4005e+00, -4.4243e-01, -1.5874e+00,\n",
      "          6.6981e-01, -6.1175e-01, -1.0460e+00, -1.6632e+00,  1.0982e+00,\n",
      "          8.8275e-01, -2.7390e-01, -8.3543e-01, -1.7947e+00, -7.7059e-01,\n",
      "         -1.0139e+00,  3.8007e-01, -7.7862e-01,  1.4766e+00, -6.9535e-01,\n",
      "         -1.6167e+00,  9.3479e-01,  3.4787e-02,  7.2238e-01,  9.1260e-01,\n",
      "          5.0928e-01,  9.5745e-01, -9.9209e-02, -2.8937e-01, -7.0353e-01,\n",
      "          1.0486e+00,  2.8489e-01, -4.2201e-02,  5.4701e-02, -1.9324e+00,\n",
      "         -3.0063e-02,  4.5810e-01,  3.5041e-01,  1.9524e-01,  2.9265e-01,\n",
      "         -5.1988e-01, -2.3442e-01, -2.9873e-01,  8.3053e-01, -1.7624e+00,\n",
      "          2.7814e-01,  1.7309e+00,  3.3866e+00, -5.6508e-01,  1.1622e+00,\n",
      "         -6.0999e-01, -9.4901e-01, -1.8121e+00, -1.9244e+00, -3.6339e-01,\n",
      "         -9.9541e-01,  2.0491e-01, -7.4582e-01,  3.5676e-01, -3.1414e-01,\n",
      "         -4.6921e-01,  2.1847e+00,  1.8892e-01, -1.9870e+00, -2.1744e-01,\n",
      "          1.1390e+00, -1.4605e+00, -1.4380e-01, -1.0215e-01, -4.7429e-01,\n",
      "         -1.7023e+00,  3.9208e-01,  8.9453e-01,  1.0652e+00,  7.7996e-01,\n",
      "         -1.8447e-01,  1.7106e+00,  2.8738e+00, -1.4810e+00,  2.2725e-01,\n",
      "         -8.0269e-01,  4.5676e-01, -7.0187e-01, -7.3739e-01, -8.0524e-01,\n",
      "          1.5141e-01,  1.5899e+00,  1.6074e-01,  5.0979e-01, -1.1816e-01,\n",
      "          6.7743e-01, -3.7146e-01, -1.7626e+00,  7.1916e-01,  4.7324e-01,\n",
      "          5.2335e-01, -1.1832e+00,  8.1736e-01,  4.0381e-01, -6.7814e-01,\n",
      "         -7.4158e-01, -4.6967e-01,  4.9686e-01,  4.5175e-01,  3.1904e-01,\n",
      "         -5.9870e-01,  4.8941e-01, -4.0622e-01,  6.7939e-01, -1.0510e+00,\n",
      "          2.0090e-01,  3.0155e-01,  5.5392e-01,  2.9466e+00, -2.7378e-01,\n",
      "         -4.1603e-01,  8.3486e-01,  6.5238e-02, -6.3359e-01, -3.6784e-01,\n",
      "         -6.2445e-01, -9.8785e-02, -1.0549e+00, -1.8353e+00, -2.2011e-01,\n",
      "          9.2529e-02,  2.9682e-01, -1.4869e-01,  1.8202e-01, -8.7079e-01,\n",
      "         -1.1240e+00, -4.4455e-01,  6.6543e-01, -1.6946e+00, -1.4109e-01,\n",
      "         -4.2925e-01, -1.3408e-02,  9.7539e-01,  8.7941e-02,  4.7559e-01,\n",
      "          1.2788e+00,  1.1080e+00,  4.0235e-01, -6.4017e-01,  6.7522e-01,\n",
      "          8.7474e-01, -7.9851e-01, -1.0100e+00,  3.8799e-01,  8.6199e-01,\n",
      "         -7.4558e-01, -1.1062e+00, -8.6227e-01, -2.8496e-02,  1.4573e+00,\n",
      "          1.3746e+00, -9.2680e-01, -1.0513e-01,  6.8265e-01, -2.5287e+00,\n",
      "          1.4470e+00, -2.0830e+00, -1.4448e+00,  4.6165e-01, -1.1854e+00,\n",
      "         -5.0597e-01, -1.2191e+00, -2.7788e-01, -6.2849e-02,  3.6139e-01,\n",
      "          8.0588e-01,  5.8459e-01,  4.6595e-01, -8.3161e-01, -4.2482e-01,\n",
      "         -1.1216e+00, -3.9623e-01, -2.0224e+00,  1.8512e+00,  1.0830e+00,\n",
      "         -1.0487e+00,  5.3261e-01,  1.2746e+00,  2.3575e-01, -6.4725e-01,\n",
      "         -8.2238e-02,  2.6726e-01,  1.7400e-01, -1.0361e+00, -1.1906e+00,\n",
      "          5.9752e-02,  1.1812e+00,  6.7115e-01,  7.7651e-01,  4.3825e-01,\n",
      "         -1.4963e-01,  1.0011e+00,  2.2533e+00,  4.0457e-01, -1.6601e-01,\n",
      "          1.0771e+00,  2.0908e-01, -2.8612e-01, -1.2791e+00,  1.0266e+00,\n",
      "          4.2908e-01, -1.9699e+00, -4.9721e-01, -1.2286e+00,  6.7408e-01,\n",
      "          7.3108e-01,  1.5055e+00, -1.2287e+00,  3.0124e-01, -7.7105e-01,\n",
      "          8.3785e-01,  2.9574e-01,  2.3867e-01, -4.0277e-01,  4.9075e-01,\n",
      "         -2.1113e+00,  1.6127e-01, -2.1150e+00,  8.0658e-02, -4.9044e-01,\n",
      "          1.0774e+00,  1.1730e-01, -4.9562e-01,  1.1149e+00,  9.4289e-01,\n",
      "          5.1737e-01,  1.6866e+00, -6.3254e-01, -2.3351e-01,  8.1591e-01,\n",
      "         -8.4440e-01, -9.4518e-01,  2.3258e+00,  4.6469e-01,  1.4318e+00,\n",
      "          1.1620e+00, -8.6130e-02,  1.7072e+00, -9.8035e-01, -1.4568e+00,\n",
      "          6.6352e-01,  2.5019e+00,  1.4468e+00, -2.2981e-01,  9.2628e-02,\n",
      "         -5.2910e-01,  1.3731e-02, -7.3364e-02,  1.2935e+00,  1.2653e-03,\n",
      "         -1.3595e+00, -1.7080e+00, -7.2112e-01,  1.1908e+00,  1.6470e-01,\n",
      "          2.7953e-01,  1.5781e+00, -1.7772e+00, -4.6683e-01,  7.6118e-01,\n",
      "          1.5730e+00,  1.6761e+00,  4.7024e-01, -3.9878e-01,  4.9325e-01,\n",
      "          3.0765e-01, -6.0682e-01,  4.7568e-01,  8.9833e-01,  1.2749e+00,\n",
      "         -4.2774e-01, -9.7685e-01,  5.6895e-01, -1.6699e-01,  4.6390e-01,\n",
      "          3.9229e-02,  1.2119e-01,  1.8291e-01, -1.2192e-01,  2.9516e-01,\n",
      "         -1.6027e+00, -1.9223e+00, -6.5409e-01, -5.8984e-01, -3.0541e-02]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "Vector len: 1000\n"
     ]
    }
   ],
   "source": [
    "# Test with Word Embedding in pytorch\n",
    "# Note 1: Usage of Word embedding in Pytorch is similar with that of Tensorflow\n",
    "# Usage:\n",
    "#  embed = Embedding(vocabulary_size, output_size, input_length)    # return an instance\n",
    "#  one_hot_vector = one_hot(word, vocabulary size)\n",
    "#  word_vector = embed(one_hot_vector)   # one_hot_vector here use index of word rather than 0,1 representation\n",
    "\n",
    "\n",
    "# Note 2: \n",
    "#     Since using word2vec, glove network to find word vector is a training process, \n",
    "#     word embedding is actually a layer in the model you need to train.\n",
    "vocab = list(vocab)\n",
    "\n",
    "vocab_size=len(vocab)\n",
    "word_to_ix = [one_hot(d, vocab_size) for d in corpus_train]\n",
    "# 2255251000100word embeddingnn.Embedding(1000, 100)\n",
    "# embeds = torch.nn.Embedding(2, 5)\n",
    "\n",
    "embeds = torch.nn.Embedding(vocab_size, 1000)\n",
    "word_idx = torch.LongTensor([vocab.index('remedy')])\n",
    "print(word_idx)\n",
    "word_embed = embeds(word_idx)\n",
    "print(word_embed)\n",
    "print(\"Vector len:\",len(word_embed[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as layers \n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42, 38], [3, 40], [7, 36], [40, 40], [12], [35], [28, 36], [39, 3], [28, 40], [36, 26, 38, 15]]\n",
      "[[42 38  0  0]\n",
      " [ 3 40  0  0]\n",
      " [ 7 36  0  0]\n",
      " [40 40  0  0]\n",
      " [12  0  0  0]\n",
      " [35  0  0  0]\n",
      " [28 36  0  0]\n",
      " [39  3  0  0]\n",
      " [28 40  0  0]\n",
      " [36 26 38 15]]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-8069d0816f30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    196\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# right now. Checking for the presence of GPUs to avoid complicating the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# TPU codepaths which can handle sparse optimizers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         self.embeddings = self.add_weight(\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mnum_gpus\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1045\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;34m\"\"\"The number of GPUs available to execute operations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_gpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m           pywrap_tfe.TFE_ContextOptionsSetLazyRemoteInputsCopy(\n\u001b[1;32m    514\u001b[0m               opts, self._lazy_remote_inputs_copy)\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-290e826f9d4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# padded_docs = pad_sequences(count_vec_train.shape[0], maxlen=max_length, padding='post')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    196\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# right now. Checking for the presence of GPUs to avoid complicating the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# TPU codepaths which can handle sparse optimizers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         self.embeddings = self.add_weight(\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mnum_gpus\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1045\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;34m\"\"\"The number of GPUs available to execute operations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_gpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m           pywrap_tfe.TFE_ContextOptionsSetLazyRemoteInputsCopy(\n\u001b[1;32m    514\u001b[0m               opts, self._lazy_remote_inputs_copy)\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable"
     ]
    }
   ],
   "source": [
    "#define deep neural network with embeddings\n",
    "max_length = 4\n",
    "input_shape = count_vec_train.shape[1]\n",
    "output_shape = 64\n",
    "# padded_docs = pad_sequences(count_vec_train.shape[0], maxlen=max_length, padding='post')\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_shape, output_shape, input_length=128 ))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categories_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "# padded_docs\n",
    "model.fit(count_vec_train, clean_data['score'], epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(count_vec_train, clean_data['score'], verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index out of range: Tried to access index 4485967 out of table with 4485966 rows. at /tmp/pip-req-build-ufslq_a9/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-99143ec486a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_vec_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 2 words in vocab, 5 dimensional embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlookup_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_vec_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhello_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhello_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range: Tried to access index 4485967 out of table with 4485966 rows. at /tmp/pip-req-build-ufslq_a9/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label types: rating from 1 to 10\n",
    "target_names = set(dataset['score'])\n",
    "target_names= list(target_names)\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91048"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(C=0.1, random_state=40).fit(tfidf_vec_train, dataset['score'])\n",
    "#train corpus score\n",
    "clf.score(tfidf_vec_train, dataset['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.51      0.44      5022\n",
      "           2       0.19      0.13      0.16      2302\n",
      "           3       0.19      0.16      0.17      2541\n",
      "           4       0.23      0.21      0.22      2635\n",
      "           7       0.19      0.18      0.19      2307\n",
      "           8       0.23      0.23      0.23      2850\n",
      "           9       0.19      0.15      0.17      2344\n",
      "          10       0.40      0.44      0.42      4999\n",
      "\n",
      "    accuracy                           0.30     25000\n",
      "   macro avg       0.25      0.25      0.25     25000\n",
      "weighted avg       0.28      0.30      0.29     25000\n",
      "\n",
      "Accuracy: \n",
      " 0.29736\n"
     ]
    }
   ],
   "source": [
    "# clf.score(tfidf_vec_test, testdata['score'])\n",
    "test_label = testdata['score']\n",
    "pred = clf.predict(tfidf_vec_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(test_label, pred,  labels = target_names))\n",
    "print(\"Accuracy: \\n\", accuracy_score(testdata['score'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90388"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression( solver = 'sag', random_state=0).fit(tfidf_vec_train, dataset['score'])\n",
    "#train corpus score\n",
    "lr_clf.score(tfidf_vec_train, dataset['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.50      0.44      5022\n",
      "           2       0.19      0.13      0.15      2302\n",
      "           3       0.19      0.15      0.17      2541\n",
      "           4       0.22      0.21      0.22      2635\n",
      "           7       0.19      0.18      0.18      2307\n",
      "           8       0.23      0.23      0.23      2850\n",
      "           9       0.19      0.14      0.16      2344\n",
      "          10       0.39      0.45      0.42      4999\n",
      "\n",
      "    accuracy                           0.30     25000\n",
      "   macro avg       0.25      0.25      0.25     25000\n",
      "weighted avg       0.28      0.30      0.28     25000\n",
      "\n",
      "Accuracy: \n",
      " 0.29512\n"
     ]
    }
   ],
   "source": [
    "test_label = testdata['score']\n",
    "lr_pred = lr_clf.predict(tfidf_vec_test)\n",
    "print(classification_report(test_label, lr_pred,  labels = target_names))\n",
    "print(\"Accuracy: \\n\", accuracy_score(testdata['score'], lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68652"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "svc_clf = LinearSVC(C=0.05).fit(tfidf_vec_train, dataset['score'])\n",
    "svc_clf.score(tfidf_vec_train, dataset['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.70      0.49      5022\n",
      "           2       0.18      0.04      0.06      2302\n",
      "           3       0.19      0.07      0.10      2541\n",
      "           4       0.23      0.15      0.18      2635\n",
      "           7       0.19      0.14      0.16      2307\n",
      "           8       0.24      0.18      0.21      2850\n",
      "           9       0.20      0.05      0.08      2344\n",
      "          10       0.37      0.61      0.46      4999\n",
      "\n",
      "    accuracy                           0.33     25000\n",
      "   macro avg       0.25      0.24      0.22     25000\n",
      "weighted avg       0.27      0.33      0.27     25000\n",
      "\n",
      "Accuracy: \n",
      " 0.32632\n"
     ]
    }
   ],
   "source": [
    "svc_pred = svc_clf.predict(tfidf_vec_test)\n",
    "test_label = testdata['score']\n",
    "print(classification_report(test_label, svc_pred,  labels = target_names))\n",
    "print(\"Accuracy: \\n\", accuracy_score(testdata['score'], svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My default: Python3.7.7",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
